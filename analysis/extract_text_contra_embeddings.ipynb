{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba438672-8a3c-4bfd-9592-141cda5a1e62",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad80b3ad-da9f-4794-bf43-b7e081f20153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Importing Libraries\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, random_split, TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.utilities.deepspeed import convert_zero_checkpoint_to_fp32_state_dict\n",
    "\n",
    "import lightning as L\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "# from lightning.pytorch.strategies import DeepSpeedStrategy\n",
    "# from lightning.pytorch.plugins.precision import DeepSpeedPrecisionPlugin\n",
    "\n",
    "# Custom library\n",
    "sys.path.append('../process/')\n",
    "from loadData import HTContraDataModule\n",
    "from contraUtilities import compute_sim_matrix, compute_target_matrix, kl_contrastive_loss, supervised_infoNCE_loss, supervised_infoNCE_loss_with_negatives\n",
    "from contraUtilities import supervised_contrastive_loss, supervised_contrastive_loss_with_negatives, create_triplets, compute_triplet_loss\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35972b6f-e518-4928-b1b5-d8eeee4d1227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the parser\n",
    "parser = argparse.ArgumentParser(description=\"Train a transformers-based classifier.\")\n",
    "\n",
    "# Add arguments to the parser\n",
    "parser.add_argument('--model_name_or_path', type=str, default=\"johngiorgi/declutr-small\")\n",
    "parser.add_argument('--tokenizer_name_or_path', type=str, default=\"johngiorgi/declutr-small\")\n",
    "parser.add_argument('--logged_entry_name', type=str, default=\"declutr-small-contra-temp:0.5-seed:1111\")\n",
    "parser.add_argument('--data_dir', type=str, default='../data/processed/')\n",
    "parser.add_argument('--demography', type=str, default='south')\n",
    "parser.add_argument('--save_dir', type=str, default=os.path.join(os.getcwd(), \"../models/text-baselines/contra-learn\"))\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--nb_epochs', type=int, default=100)\n",
    "parser.add_argument('--max_seq_length', type=int, default=512)\n",
    "parser.add_argument('--sample_unit_size', type=int, default=2)\n",
    "parser.add_argument('--emb_len', type=int, default=768)\n",
    "parser.add_argument('--hidden_dim', type=int, default=512)\n",
    "parser.add_argument('--patience', type=int, default=5)\n",
    "parser.add_argument('--seed', type=int, default=1111)\n",
    "parser.add_argument('--warmup_steps', type=int, default=0)\n",
    "parser.add_argument('--grad_steps', type=int, default=4)\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0001)\n",
    "parser.add_argument('--dropout', type=float, default=0.3)\n",
    "parser.add_argument('--train_data_percentage', type=float, default=1.0)\n",
    "parser.add_argument('--adam_epsilon', type=float, default=1e-6)\n",
    "parser.add_argument('--min_delta_change', type=float, default=0.5)\n",
    "parser.add_argument('--temp', type=float, default=0.5)\n",
    "parser.add_argument('--weight_decay', type=float, default=0.01)\n",
    "parser.add_argument('--nb_triplets', type=int, default=1)\n",
    "\n",
    "# Simulate the command line inputs (change these strings to simulate different command line arguments)\n",
    "input_args = [\n",
    "    '--model_name_or_path', 'johngiorgi/declutr-small',\n",
    "    '--tokenizer_name_or_path', 'johngiorgi/declutr-small',\n",
    "    '--logged_entry_name', 'declutr-small-contra-temp:0.5-seed:1111',\n",
    "    '--data_dir', '../data/processed/',\n",
    "    '--demography', 'south',\n",
    "    '--save_dir', os.path.join(os.getcwd(), \"../models/text-baselines/contra-learn\"),\n",
    "    '--batch_size', '32',\n",
    "    '--nb_epochs', '2',\n",
    "    '--max_seq_length', '512',\n",
    "    '--sample_unit_size', '2',\n",
    "    '--emb_len', '768',\n",
    "    '--hidden_dim', '512',\n",
    "    '--patience', '5',\n",
    "    '--seed', '1111',\n",
    "    '--warmup_steps', '0',\n",
    "    '--grad_steps', '4',\n",
    "    '--learning_rate', '0.0001',\n",
    "    '--dropout', '0.3',\n",
    "    '--train_data_percentage', '1.0',\n",
    "    '--adam_epsilon', '1e-6',\n",
    "    '--min_delta_change', '0.5',\n",
    "    '--temp', '0.5',\n",
    "    '--weight_decay', '0.01',\n",
    "    '--nb_triplets', '1'\n",
    "]\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args(input_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78823049-c91c-4fa9-81f2-2576e6d0480e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.pooling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a150fc7-6266-48a0-8d4a-10e9e61ff940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1111"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting seed value for reproducibility    \n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "seed_everything(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfc423b6-25bc-43b9-b28a-346dc7e0c6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "381e5192-9a1f-4008-a5f7-5f96d8c8889d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating directories\n",
    "directory = os.path.join(args.save_dir, \"seed:\" + str(args.seed), \"lr-\" + str(args.learning_rate), args.demography, args.model_name_or_path.split(\"/\")[-1])\n",
    "Path(directory).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28640ee3-1d4c-4020-beb4-30b11971d5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "dm = HTContraDataModule(file_dir=os.path.join(args.data_dir, args.demography + '.csv'), tokenizer_name_or_path=args.tokenizer_name_or_path, seed=args.seed, train_batch_size=args.batch_size, \n",
    "                        eval_batch_size=args.batch_size)\n",
    "dm.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "956334a1-56a6-4924-922b-b9cf24d1af30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.num_classes = pd.read_csv(os.path.join(args.data_dir, args.demography + '.csv')).VENDOR.nunique()\n",
    "args.num_training_steps = len(dm.train_dataloader()) * args.nb_epochs\n",
    "# Setting the warmup steps to 1/10th the size of training data\n",
    "args.warmup_steps = int(len(dm.train_dataloader()) * 10/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b054b0-dbe7-4f93-a9f0-a04fbcd2eb1d",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b5e2023-fa79-434e-9ee4-97a87ce45c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from transformers import RobertaModel\n",
    "from transformers import AutoModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48f85526-bb56-4107-8472-ee1fe70b1ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Head for getting sentence representations over RoBERTa/BERT's CLS representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dense(features)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Similarity(nn.Module):\n",
    "    \"\"\"\n",
    "    Dot product or cosine similarity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temp):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "        self.cos = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.cos(x, y) / self.temp\n",
    "\n",
    "class Pooler(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameter-free poolers to get the sentence embedding\n",
    "    'cls': [CLS] representation with BERT/RoBERTa's MLP pooler.\n",
    "    'cls_before_pooler': [CLS] representation without the original MLP pooler.\n",
    "    'avg': average of the last layers' hidden states at each token.\n",
    "    'avg_top2': average of the last two layers.\n",
    "    'avg_first_last': average of the first and the last layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, pooler_type):\n",
    "        super().__init__()\n",
    "        self.pooler_type = pooler_type\n",
    "        assert self.pooler_type in [\"cls\", \"cls_before_pooler\", \"avg\", \"avg_top2\", \"avg_first_last\"], \"unrecognized pooling type %s\" % self.pooler_type\n",
    "\n",
    "    def forward(self, attention_mask, outputs):\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        pooler_output = outputs.pooler_output\n",
    "        hidden_states = outputs.hidden_states\n",
    "\n",
    "        if self.pooler_type in ['cls_before_pooler', 'cls']:\n",
    "            return last_hidden[:, 0]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "def cl_init(cls, pooler_type_, config, temp_):\n",
    "    \"\"\"\n",
    "    Contrastive learning class init function.\n",
    "    \"\"\"\n",
    "    cls.pooler_type = pooler_type_\n",
    "    cls.pooler = Pooler(pooler_type_)\n",
    "    cls.mlp = MLPLayer(config)\n",
    "    cls.sim = Similarity(temp=temp_)\n",
    "    cls.init_weights()\n",
    "\n",
    "def cl_forward(cls, encoder, pooler_type, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, \n",
    "                labels=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "    #import ipdb; ipdb.set_trace();\n",
    "    return_dict = return_dict if return_dict is not None else cls.config.use_return_dict\n",
    "    batch_size = int(input_ids.size(0))\n",
    "    \n",
    "    # mlm_outputs = None\n",
    "    # Flatten input for encoding\n",
    "    # input_ids = input_ids.view((-1, input_ids.size(-1))) # (bs * num_sent, len)\n",
    "    # attention_mask = attention_mask.view((-1, attention_mask.size(-1))) # (bs * num_sent len)\n",
    "    # if token_type_ids is not None:\n",
    "    #     token_type_ids = token_type_ids.view((-1, token_type_ids.size(-1))) # (bs * num_sent, len)\n",
    "\n",
    "    # Get raw embeddings\n",
    "    outputs = encoder(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds,\n",
    "                        output_attentions=output_attentions, output_hidden_states=False if pooler_type == 'cls' else True, return_dict=True)\n",
    "\n",
    "    # Pooling\n",
    "    pooler_output = cls.pooler(attention_mask, outputs)\n",
    "    pooler_output = pooler_output.view((batch_size, pooler_output.size(-1))) # (bs, num_sent, hidden)\n",
    "\n",
    "    # If using \"cls\", we add an extra MLP layer\n",
    "    # (same as BERT's original implementation) over the representation.\n",
    "    if cls.pooler_type == \"cls\":\n",
    "        pooler_output = cls.mlp(pooler_output)\n",
    "\n",
    "    return pooler_output\n",
    "\n",
    "def sentemb_forward(cls, encoder, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, \n",
    "                    inputs_embeds=None, labels=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
    "\n",
    "    return_dict = return_dict if return_dict is not None else cls.config.use_return_dict\n",
    "\n",
    "    outputs = encoder(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask,\n",
    "                        inputs_embeds=inputs_embeds, output_attentions=output_attentions, output_hidden_states=True if cls.pooler_type in ['avg_top2', 'avg_first_last'] else False,\n",
    "                        return_dict=True)\n",
    "\n",
    "    pooler_output = cls.pooler(attention_mask, outputs)\n",
    "    if cls.pooler_type == \"cls\":\n",
    "        pooler_output = cls.mlp(pooler_output)\n",
    "\n",
    "    if not return_dict:\n",
    "        return (outputs[0], pooler_output) + outputs[2:]\n",
    "\n",
    "    return BaseModelOutputWithPoolingAndCrossAttentions(pooler_output=pooler_output, last_hidden_state=outputs.last_hidden_state, \n",
    "                                                        hidden_states=outputs.hidden_states)\n",
    "\n",
    "def compute_sim_matrix(feats):\n",
    "    \"\"\"\n",
    "    Takes in a batch of features of size (bs, feat_len).\n",
    "    \"\"\"\n",
    "    sim_matrix = F.cosine_similarity(feats.unsqueeze(2).expand(-1, -1, feats.size(0)),\n",
    "                                     feats.unsqueeze(2).expand(-1, -1, feats.size(0)).transpose(0, 2),\n",
    "                                     dim=1)\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "def compute_target_matrix(labels):\n",
    "    \"\"\"\n",
    "    Computes a target matrix for contrastive learning based on class labels.\n",
    "\n",
    "    This function generates a square matrix where each element (i, j) indicates whether \n",
    "    the labels for samples i and j are the same. This binary matrix serves as the target \n",
    "    for similarity in contrastive learning tasks, facilitating the training to learn \n",
    "    embeddings that are closer for similar (same label) instances and further apart for \n",
    "    dissimilar (different label) ones.\n",
    "\n",
    "    Parameters:\n",
    "        labels (torch.Tensor): A 1D tensor containing the class labels for a batch of samples.\n",
    "                               The tensor should have a shape of (bs,), where bs is the batch size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 2D square tensor of shape (bs, bs) where each element is 1.0 if the \n",
    "                      corresponding labels are the same, and 0.0 otherwise. This tensor is of\n",
    "                      type float.\n",
    "    \"\"\"\n",
    "    label_matrix = labels.unsqueeze(-1).expand((labels.shape[0], labels.shape[0]))\n",
    "    trans_label_matrix = torch.transpose(label_matrix, 0, 1)\n",
    "    target_matrix = (label_matrix == trans_label_matrix).type(torch.float)\n",
    "\n",
    "    return target_matrix\n",
    "\n",
    "\n",
    "def contrastive_loss(pred_sim_matrix, target_matrix, temperature, labels):\n",
    "    return F.kl_div(F.softmax(pred_sim_matrix / temperature).log(), F.softmax(target_matrix / temperature),\n",
    "                    reduction=\"batchmean\", log_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7aa1ad41-683a-4357-9b0e-125f3acce410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def supervised_info_nce_loss(features, labels, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Computes the Supervised InfoNCE loss using class labels to determine positive and negative pairs.\n",
    "\n",
    "    Args:\n",
    "        features (torch.Tensor): Embeddings of shape (N, D) where N is batch size and D is embedding dimension.\n",
    "        labels (torch.Tensor): Corresponding labels of shape (N,).\n",
    "        temperature (float): A temperature scaling factor to soften the softmax output.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The computed loss.\n",
    "    \"\"\"\n",
    "    device = features.device\n",
    "    n_samples = features.size(0)\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "\n",
    "    # Normalize the features to simplify the cosine similarity calculation\n",
    "    features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = torch.mm(features, features.T) / temperature\n",
    "\n",
    "    # Create a mask to identify positive and negative samples\n",
    "    positive_mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "    # Subtract large value from diagonal to ignore self-comparison\n",
    "    logits_mask = torch.scatter(\n",
    "        torch.ones_like(similarity_matrix),\n",
    "        1,\n",
    "        torch.arange(n_samples).view(-1, 1).to(device),\n",
    "        0\n",
    "    )\n",
    "    masked_logits = similarity_matrix * logits_mask\n",
    "\n",
    "    # Compute log-sum-exp across all samples (for denominator of softmax)\n",
    "    exp_logits = torch.exp(masked_logits)\n",
    "    log_prob = similarity_matrix - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "    # Compute mean of log-likelihood over positive samples\n",
    "    mean_log_prob_pos = (positive_mask * log_prob).sum(1) / positive_mask.sum(1)\n",
    "\n",
    "    # Loss is negative log of mean positive log-probabilities\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b9dc4dc-e843-43e5-949d-b50b13f1cfb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def supervised_info_nce_loss_with_hard_negatives(features, labels, temperature=0.1, num_hard_negatives=5, epsilon=1e-6):\n",
    "    device = features.device\n",
    "    n_samples = features.size(0)\n",
    "    labels = labels.view(-1, 1)\n",
    "\n",
    "    # Normalize features to the unit sphere to simplify cosine similarity\n",
    "    features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity matrix and scale by temperature\n",
    "    similarity_matrix = torch.mm(features, features.T) / temperature\n",
    "\n",
    "    # Mask to select positive samples\n",
    "    positive_mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "    # Mask to exclude self-similarity\n",
    "    diagonal_mask = torch.eye(n_samples, device=device).bool()\n",
    "    positive_mask[diagonal_mask] = 0\n",
    "\n",
    "    # Hard negatives: select the top-k negative examples (excluding self)\n",
    "    negative_mask = 1 - positive_mask\n",
    "    negative_mask[diagonal_mask] = 0\n",
    "    top_negatives = torch.topk(similarity_matrix * negative_mask, k=num_hard_negatives, dim=1).values\n",
    "\n",
    "    # Compute log-sum-exp for normalization over chosen hard negatives and all positives\n",
    "    positive_counts = positive_mask.sum(1).int().tolist()  # Convert to int here\n",
    "    positives = similarity_matrix[positive_mask.bool()].split(positive_counts)  # Split into lists of positives per sample\n",
    "    positives_padded = torch.nn.utils.rnn.pad_sequence(positives, batch_first=True, padding_value=-float('Inf'))  # Pad sequences to allow concatenation\n",
    "\n",
    "    max_sim, _ = torch.max(torch.cat([positives_padded, top_negatives], dim=1), dim=1, keepdim=True)\n",
    "    exp_sim_sum = torch.exp(similarity_matrix - max_sim).clamp(min=epsilon).sum(1, keepdim=True)\n",
    "\n",
    "    # Compute log probability of positive samples\n",
    "    log_prob_pos = torch.log(torch.exp(positives_padded - max_sim).clamp(min=epsilon).sum(1, keepdim=True) / exp_sim_sum + epsilon)\n",
    "\n",
    "    # Negative log likelihood\n",
    "    loss = -log_prob_pos.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0cebb9a-48ec-4735-952e-10f7db471cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def supervised_contrastive_loss(features, labels, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Computes the supervised contrastive loss.\n",
    "\n",
    "    Parameters:\n",
    "        features (torch.Tensor): The embeddings for the batch, shape (N, D)\n",
    "                                 where N is the batch size and D is the dimension of the embeddings.\n",
    "        labels (torch.Tensor): The class labels for the batch, shape (N,)\n",
    "                               with each value in range [0, C-1] where C is the number of classes.\n",
    "        temperature (float): A temperature scaling factor to adjust the sharpness of\n",
    "                             the softmax distribution.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The computed supervised contrastive loss.\n",
    "    \"\"\"\n",
    "    device = features.device\n",
    "    labels = labels.to(device)\n",
    "    batch_size = features.shape[0]\n",
    "\n",
    "    # Normalize the features to the unit sphere\n",
    "    features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "    # Compute the cosine similarity matrix\n",
    "    sim_matrix = torch.mm(features, features.t()) / temperature\n",
    "\n",
    "    # Mask for identifying positive pairs (excluding the diagonal)\n",
    "    pos_mask = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "    pos_mask.fill_diagonal_(0)\n",
    "\n",
    "    # Compute the logits\n",
    "    exp_sim = torch.exp(sim_matrix) * pos_mask\n",
    "\n",
    "    # Sum of exps for all positive pairs\n",
    "    sum_pos = exp_sim.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Log-sum-exp trick for numerical stability\n",
    "    logits_max, _ = torch.max(sim_matrix, dim=1, keepdim=True)\n",
    "    log_prob_denom = torch.log(torch.exp(sim_matrix - logits_max).sum(dim=1, keepdim=True) + 1e-12) + logits_max\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = -torch.log(sum_pos / torch.exp(log_prob_denom) + 1e-12)\n",
    "    loss = loss.mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0b4964f5-1fc3-43fe-9530-c038b3ade6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def supervised_contrastive_loss_with_hard_negatives(features, labels, temperature=0.1, num_hard_negatives=0, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the supervised contrastive loss with hard negatives, adding safeguards against numerical instability.\n",
    "\n",
    "    Parameters:\n",
    "        features (torch.Tensor): Embeddings of shape (N, D).\n",
    "        labels (torch.Tensor): Class labels of shape (N,).\n",
    "        temperature (float): Temperature scaling factor.\n",
    "        num_hard_negatives (int): Number of hard negatives to consider.\n",
    "        eps (float): Small epsilon value for numerical stability in log operations.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The computed supervised contrastive loss.\n",
    "    \"\"\"\n",
    "    device = features.device\n",
    "    labels = labels.to(device)\n",
    "    batch_size = features.shape[0]\n",
    "\n",
    "    # Normalize the features to the unit sphere\n",
    "    features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "    # Compute the cosine similarity matrix and apply temperature scaling\n",
    "    sim_matrix = torch.mm(features, features.t()) / temperature\n",
    "\n",
    "    # Mask for identifying positive pairs (excluding the diagonal)\n",
    "    pos_mask = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "    pos_mask.fill_diagonal_(0)\n",
    "\n",
    "    # Mask for identifying negatives\n",
    "    neg_mask = labels.unsqueeze(1) != labels.unsqueeze(0)\n",
    "\n",
    "    # Select hard negatives: top 'num_hard_negatives' from each row, considering only negatives\n",
    "    negative_scores = sim_matrix * neg_mask.float()\n",
    "    top_negatives, _ = torch.topk(negative_scores, k=num_hard_negatives, dim=1)\n",
    "\n",
    "    # Sum of exps for all positive pairs and hard negatives\n",
    "    exp_pos = torch.exp(sim_matrix * pos_mask.float()).sum(dim=1, keepdim=True)\n",
    "    exp_hard_neg = torch.exp(top_negatives)\n",
    "\n",
    "    # Log-sum-exp trick for numerical stability: max_sim for each row\n",
    "    max_sim, _ = torch.max(sim_matrix, dim=1, keepdim=True)\n",
    "    exp_sum = torch.exp(sim_matrix - max_sim).sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Combine positives and hard negatives in the denominator\n",
    "    denom = exp_sum + exp_hard_neg.sum(dim=1, keepdim=True) - torch.exp(top_negatives - max_sim)\n",
    "\n",
    "    # Log probability of positive pairs\n",
    "    log_prob_pos = torch.log(exp_pos / (denom + eps) + eps)\n",
    "\n",
    "    # Compute the mean of negative log probabilities across the batch\n",
    "    loss = -log_prob_pos.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9a1d17f5-b8b6-4200-9677-0e51af8667f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeclutrClassifier(nn.Module):\n",
    "    def __init__(self, model, classifier):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.fc = classifier\n",
    "\n",
    "    def forward(self, x, pooling, return_feat=False):\n",
    "        # x is a tokenized input\n",
    "        # features = self.model(input_ids=x[0], token_type_ids=x[1], attention_mask=x[2])\n",
    "        features = self.model(input_ids=x[0], attention_mask=x[2])\n",
    "\n",
    "        # Get the last hidden state\n",
    "        last_hidden_state = features.last_hidden_state\n",
    "\n",
    "        if pooling == True:            \n",
    "            # [CLS] token representation - generally the first token in the sequence\n",
    "            cls_representation = last_hidden_state[:, 0, :]\n",
    "            \n",
    "            # Mean pooling - mean over the sequence dimension, ignoring padding (use attention_mask)\n",
    "            expanded_attention_mask = x[2].unsqueeze(-1).expand_as(last_hidden_state)\n",
    "            sum_hidden_state = torch.sum(last_hidden_state * expanded_attention_mask, dim=1)\n",
    "            sum_mask = torch.clamp(expanded_attention_mask.sum(1), min=1e-9)\n",
    "            mean_pooled = sum_hidden_state / sum_mask\n",
    "            last_layer_representation = mean_pooled\n",
    "        else:\n",
    "            # Flattenning the output of last layer\n",
    "            last_layer_representation = last_hidden_state.view(last_hidden_state.size(0), -1)  # Reshape to [batch_size, features]\n",
    "        \n",
    "        out = self.fc(last_layer_representation)\n",
    "\n",
    "        if return_feat:\n",
    "            return out, cls_representation, last_layer_representation\n",
    "\n",
    "        return out\n",
    "\n",
    "\"\"\"class DeclutrClassifier(nn.Module):\n",
    "    def __init__(self, model, classifier):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.fc = classifier\n",
    "\n",
    "    def forward(self, x, pooling, return_feat=False):\n",
    "        # x is a tokenized input\n",
    "        # feature = self.model(input_ids=x[0], token_type_ids=x[1], attention_mask=x[2])\n",
    "        feature = self.model(input_ids=x[0], attention_mask=x[2])\n",
    "        # out = self.fc(feature.pooler_output.flatten(1))       # not good for our task     # (BS, E)\n",
    "        hidden_states = feature[\"hidden_states\"]\n",
    "        print(\"Output to Logistic Regression;\", feature.last_hidden_state.flatten(1).shape)\n",
    "        out = self.fc(feature.last_hidden_state.flatten(1))  # (BS, T, E)\n",
    "        if return_feat:\n",
    "            return out, hidden_states, feature.last_hidden_state.flatten(1)\n",
    "        return out\n",
    "\"\"\"\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0):\n",
    "        super().__init__()\n",
    "        # print(f'Logistic Regression classifier of dim ({in_dim} {hid_dim} {out_dim})')\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_dim, hid_dim, bias=True),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hid_dim, out_dim, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_feat=False):\n",
    "        out = self.nn(x)\n",
    "        if return_feat:\n",
    "            return out, x\n",
    "        return out\n",
    "\n",
    "class HTContraClassifierModel(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        if isinstance(args, tuple) and len(args) > 0: \n",
    "            self.args = args[0]\n",
    "            self.hparams.learning_rate = self.args.learning_rate\n",
    "            self.hparams.eps = self.args.adam_epsilon\n",
    "            self.hparams.weight_decay = self.args.weight_decay\n",
    "            self.hparams.model_name_or_path = self.args.model_name_or_path\n",
    "            self.hparams.num_classes = self.args.num_classes\n",
    "            self.hparams.num_training_steps = self.args.num_training_steps\n",
    "            self.hparams.warmup_steps = self.args.warmup_steps\n",
    "            self.hparams.emb_len = self.args.emb_len\n",
    "            self.hparams.max_seq_length = self.args.max_seq_length\n",
    "            self.hparams.hidden_dim = self.args.hidden_dim\n",
    "            self.hparams.dropout = self.args.dropout\n",
    "            self.hparams.nb_epochs = self.args.nb_epochs\n",
    "            self.hparams.temp = self.args.temp\n",
    "            self.hparams.coefficient = self.args.coefficient\n",
    "            self.hparams.num_hard_negatives = self.args.num_hard_negatives\n",
    "            self.hparams.loss1_type = self.args.loss1_type\n",
    "            self.hparams.loss2_type = self.args.loss2_type\n",
    "            self.hparams.pooling = self.args.pooling\n",
    "            self.hparams.num_triplets_per_sample = self.args.nb_triplets\n",
    "        \n",
    "        # freeze\n",
    "        self._frozen = False\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Loading model\n",
    "        self.model = AutoModel.from_pretrained(self.hparams.model_name_or_path)\n",
    "        \n",
    "        if self.hparams.pooling == True:\n",
    "            self.model = DeclutrClassifier(self.model, LogisticRegression(self.hparams.emb_len, \n",
    "                                                                          self.hparams.hidden_dim, self.hparams.num_classes, \n",
    "                                                                          dropout=self.hparams.dropout))\n",
    "        else:\n",
    "             self.model = DeclutrClassifier(self.model, LogisticRegression(self.hparams.emb_len * self.hparams.max_seq_length, \n",
    "                                                                      self.hparams.hidden_dim, self.hparams.num_classes, \n",
    "                                                                      dropout=self.hparams.dropout))\n",
    "        # self.model = nn.DataParallel(self.model).cuda()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids, token_ids, attention_mask, y = batch\n",
    "        x, y = (input_ids, token_ids, attention_mask), y\n",
    "        \n",
    "        pred, _, feats = self.model(x, self.hparams.pooling, return_feat=True)\n",
    "        \n",
    "        if self.hparams.loss1_type == \"CE\":\n",
    "            loss_1 = self.criterion(pred, y.long())\n",
    "        else:\n",
    "            loss_1 = 0\n",
    "            self.hparams.coefficient = 1\n",
    "\n",
    "        if self.hparams.loss2_type == \"KL\":\n",
    "            mask = y.clone().cpu().apply_(lambda x: x not in []).type(torch.bool)\n",
    "            feats, pred, y = feats[mask], pred[mask], y[mask]\n",
    "\n",
    "            sim_matrix = compute_sim_matrix(feats)\n",
    "            target_matrix = compute_target_matrix(y)\n",
    "            loss_contrastive = kl_contrastive_loss(sim_matrix, target_matrix, self.hparams.temp, y)\n",
    "\n",
    "        elif self.hparams.loss2_type == \"infoNCE-negatives\":\n",
    "            loss_contrastive = supervised_infoNCE_loss_with_negatives(feats, y, self.hparams.temp)\n",
    "\n",
    "        elif self.hparams.loss2_type == \"SupCon-negatives\":\n",
    "            loss_contrastive = supervised_contrastive_loss_with_negatives(feats, y, self.hparams.temp)\n",
    "\n",
    "        elif self.hparams.loss2_type == \"triplet\":\n",
    "            triplet_loss, _ = compute_triplet_loss(feats, y, self.hparams.num_triplets_per_sample)\n",
    "            loss_contrastive = triplet_loss\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Loss2 type can only be between KL, infoNCE, infoNCE-negatives (with in-batch negatives), SupCon, triplet, and SupCon-negatives (with in-batch negatives). Other losses have not been implemented.\")\n",
    "        \n",
    "        total_loss = loss_1 + self.hparams.coefficient * loss_contrastive\n",
    "        \n",
    "        return pred, feats, y, total_loss\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class stipulates you to overwrite. This we do here, by virtue of this definition\n",
    "        _, _, _, train_loss = self(batch)  # self refers to the model, which in turn acceses the forward method\n",
    "        self.log_dict({\"train_loss\": train_loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return train_loss\n",
    "        # the training_step method expects a dictionary, which should at least contain the loss\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class  wants you to overwrite, in case you want to do validation. This we do here, by virtue of this definition.\n",
    "\n",
    "        pred, _, y, val_loss = self(batch)\n",
    "        # self refers to the model, which in turn accesses the forward method\n",
    "\n",
    "        # Evaluating the performance\n",
    "        predictions = torch.argmax(pred, dim=1)\n",
    "        balanced_accuracy = balanced_accuracy_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), adjusted=True)\n",
    "        macro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='macro')\n",
    "        micro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='micro')\n",
    "        weighted_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='weighted')        \n",
    "        \n",
    "        self.log_dict({\"val_loss\": val_loss, 'accuracy': balanced_accuracy, 'macro-F1': macro_accuracy, 'micro-F1': micro_accuracy, 'weighted-F1':weighted_accuracy}, \n",
    "                       on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        \n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class  wants you to overwrite, in case you want to do test. This we do here, by virtue of this definition.\n",
    "\n",
    "        pred, _, y, test_loss = self(batch)\n",
    "        # self refers to the model, which in turn accesses the forward method\n",
    "\n",
    "        # Evaluating the performance\n",
    "        predictions = torch.argmax(pred, dim=1)\n",
    "        balanced_accuracy = balanced_accuracy_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), adjusted=True)\n",
    "        macro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='macro')\n",
    "        micro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='micro')\n",
    "        weighted_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='weighted')\n",
    "        \n",
    "        self.log_dict({\"test_loss\": test_loss, 'accuracy': balanced_accuracy, 'macro-F1': macro_accuracy, 'micro-F1': micro_accuracy, 'weighted-F1':weighted_accuracy}, \n",
    "                      on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return test_loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class  wants you to overwrite, in case you want to do validation. This we do here, by virtue of this definition.\n",
    "        return None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # The configure_optimizers is a (virtual) method, specified in the interface, that the\n",
    "        # pl.LightningModule class wants you to overwrite.\n",
    "\n",
    "        # In this case we define that some parameters are optimized in a different way than others. In\n",
    "        # particular we single out parameters that have 'bias', 'LayerNorm.weight' in their names. For those\n",
    "        # we do not use an optimization technique called weight decay.\n",
    "\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "        optimizer_grouped_parameters = [{'params': [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay':self.hparams.weight_decay}, \n",
    "                                        {'params': [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.eps)\n",
    "        # optimizer = DeepSpeedCPUAdam(optimizer_grouped_parameters, adamw_mode=True, lr=self.hparams.learning_rate, betas=(0.9, 0.999), eps=self.hparams.eps)\n",
    "\n",
    "        # We also use a scheduler that is supplied by transformers.\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.hparams.num_training_steps)\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.nb_epochs)\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def freeze(self) -> None:\n",
    "        # freeze all layers, except the final classifier layers\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'classifier' not in name:  # classifier layer\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self._frozen = True\n",
    "\n",
    "    def unfreeze(self) -> None:\n",
    "        if self._frozen:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if 'classifier' not in name:  # classifier layer\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        self._frozen = False\n",
    "\n",
    "    def train_epoch_start(self):\n",
    "        \"\"\"pytorch lightning hook\"\"\"\n",
    "        if self.current_epoch < self.hparams.nr_frozen_epochs:\n",
    "            self.freeze()\n",
    "\n",
    "        if self.current_epoch >= self.hparams.nr_frozen_epochs:\n",
    "            self.unfreeze() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ecd9f05-2f1d-4946-a126-e35bb6e24727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Python version: 3.9\n",
    "Description: Contains helper classes and functions to load a Declutr-small model with supervised contrastive loss into the LightningModule.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from transformers import RobertaModel\n",
    "from transformers import AutoModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# from deepspeed.ops.adam import DeepSpeedCPUAdam\n",
    "\n",
    "# Custom library\n",
    "sys.path.append('../process/')\n",
    "from contraUtilities import compute_sim_matrix, compute_target_matrix, kl_contrastive_loss, supervised_infoNCE_loss, supervised_infoNCE_loss_with_negatives\n",
    "\n",
    "def supervised_contrastive_loss_with_negatives(features, labels, temperature=0.5, num_hard_negatives=5, eps=1e-8):\n",
    "    device = features.device\n",
    "    labels = labels.to(device)\n",
    "    batch_size = features.shape[0]\n",
    "\n",
    "    # Normalize the features to the unit sphere\n",
    "    features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "    # Compute the cosine similarity matrix and apply temperature scaling\n",
    "    sim_matrix = torch.mm(features, features.t())\n",
    "    sim_matrix = torch.clamp(sim_matrix, min=-10, max=10) / temperature  # Clamping extreme values\n",
    "\n",
    "    # Mask for identifying positive pairs (excluding the diagonal)\n",
    "    pos_mask = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "    pos_mask.fill_diagonal_(0)\n",
    "\n",
    "    # Mask for identifying negatives\n",
    "    neg_mask = labels.unsqueeze(1) != labels.unsqueeze(0)\n",
    "\n",
    "    # Select hard negatives: top 'num_hard_negatives' from each row, considering only negatives\n",
    "    negative_scores = sim_matrix * neg_mask.float()\n",
    "    \n",
    "    # Adjust num_hard_negatives if it exceeds the number of valid negative samples\n",
    "    k = min(num_hard_negatives, neg_mask.sum(dim=1).min().item())\n",
    "    top_negatives, _ = torch.topk(negative_scores, k=k, dim=1)\n",
    "\n",
    "    # Log-sum-exp trick for numerical stability: max_sim for each row\n",
    "    max_sim, _ = torch.max(sim_matrix, dim=1, keepdim=True)\n",
    "    exp_sim_matrix = torch.exp(sim_matrix - max_sim)\n",
    "\n",
    "    # Sum of exps for positive and hard negative pairs\n",
    "    exp_pos = (exp_sim_matrix * pos_mask.float()).sum(dim=1, keepdim=True)\n",
    "    exp_hard_neg = torch.exp(top_negatives - max_sim)\n",
    "\n",
    "    # Combine positives and hard negatives in the denominator\n",
    "    denom = exp_pos + exp_hard_neg.sum(dim=1, keepdim=True) + torch.exp(negative_scores - max_sim).sum(dim=1, keepdim=True) - exp_hard_neg\n",
    "\n",
    "    # Log probability of positive pairs\n",
    "    log_prob_pos = torch.log(exp_pos / (denom + eps) + eps)\n",
    "\n",
    "    # Compute the mean of negative log probabilities across the batch\n",
    "    loss = -log_prob_pos.mean()\n",
    "    return loss\n",
    "    \n",
    "def create_triplets(embeddings, labels, num_triplets_per_sample):\n",
    "    triplets = []\n",
    "    for i in range(len(labels)):\n",
    "        anchor = embeddings[i]\n",
    "        pos_indices = torch.where(labels == labels[i])[0]\n",
    "        neg_indices = torch.where(labels != labels[i])[0]\n",
    "        \n",
    "        # Ensure there are enough positive samples\n",
    "        if len(pos_indices) <= 1:\n",
    "            continue\n",
    "        \n",
    "        # Ensure there are enough negative samples\n",
    "        if len(neg_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Select a single positive sample\n",
    "        pos_index = pos_indices[pos_indices != i][torch.randint(len(pos_indices)-1, (1,)).item()]\n",
    "        positive = embeddings[pos_index]\n",
    "\n",
    "        # Create multiple triplets with different negative samples\n",
    "        for _ in range(num_triplets_per_sample):\n",
    "            neg_index = neg_indices[torch.randint(len(neg_indices), (1,)).item()]\n",
    "            negative = embeddings[neg_index]\n",
    "\n",
    "            triplets.append((anchor, positive, negative))\n",
    "    \n",
    "    if len(triplets) == 0:\n",
    "        return None\n",
    "    \n",
    "    anchor, positive, negative = zip(*triplets)\n",
    "    return torch.stack(anchor), torch.stack(positive), torch.stack(negative)\n",
    "\n",
    "def compute_triplet_loss(embeddings, labels, num_triplets_per_sample, margin=1.0):\n",
    "    triplets = create_triplets(embeddings, labels, num_triplets_per_sample)\n",
    "    if triplets is None:\n",
    "        return torch.tensor(0.0, requires_grad=True), None\n",
    "    \n",
    "    anchor, positive, negative = triplets\n",
    "\n",
    "    pos_dist = 1 - F.cosine_similarity(anchor, positive)\n",
    "    neg_dist = 1 - F.cosine_similarity(anchor, negative)\n",
    "    triplet_loss = F.relu(pos_dist - neg_dist + margin)\n",
    "\n",
    "    return triplet_loss.mean(), triplet_loss\n",
    "\n",
    "class DeclutrClassifier(nn.Module):\n",
    "    def __init__(self, model, classifier):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.fc = classifier\n",
    "\n",
    "    def forward(self, x, pooling, return_feat=False):\n",
    "        # x is a tokenized input\n",
    "        # features = self.model(input_ids=x[0], token_type_ids=x[1], attention_mask=x[2])\n",
    "        features = self.model(input_ids=x[0], attention_mask=x[2])\n",
    "\n",
    "        # Get the last hidden state\n",
    "        last_hidden_state = features.last_hidden_state\n",
    "\n",
    "        if pooling == True:            \n",
    "            # [CLS] token representation - generally the first token in the sequence\n",
    "            cls_representation = last_hidden_state[:, 0, :]\n",
    "            \n",
    "            # Mean pooling - mean over the sequence dimension, ignoring padding (use attention_mask)\n",
    "            expanded_attention_mask = x[2].unsqueeze(-1).expand_as(last_hidden_state)\n",
    "            sum_hidden_state = torch.sum(last_hidden_state * expanded_attention_mask, dim=1)\n",
    "            sum_mask = torch.clamp(expanded_attention_mask.sum(1), min=1e-9)\n",
    "            mean_pooled = sum_hidden_state / sum_mask\n",
    "            last_layer_representation = mean_pooled\n",
    "        else:\n",
    "            # Flattenning the output of last layer\n",
    "            last_layer_representation = last_hidden_state.view(last_hidden_state.size(0), -1)  # Reshape to [batch_size, features]\n",
    "        \n",
    "        out = self.fc(last_layer_representation)\n",
    "\n",
    "        if return_feat:\n",
    "            return out, cls_representation, last_layer_representation\n",
    "\n",
    "        return out\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout=0):\n",
    "        super().__init__()\n",
    "        # print(f'Logistic Regression classifier of dim ({in_dim} {hid_dim} {out_dim})')\n",
    "\n",
    "        self.nn = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_dim, hid_dim, bias=True),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(hid_dim, out_dim, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_feat=False):\n",
    "        out = self.nn(x)\n",
    "        if return_feat:\n",
    "            return out, x\n",
    "        return out\n",
    "        \n",
    "\n",
    "class HTContraClassifierModel(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        if isinstance(args, tuple) and len(args) > 0: \n",
    "            self.args = args[0]\n",
    "            self.hparams.learning_rate = self.args.learning_rate\n",
    "            self.hparams.eps = self.args.adam_epsilon\n",
    "            self.hparams.weight_decay = self.args.weight_decay\n",
    "            self.hparams.model_name_or_path = self.args.model_name_or_path\n",
    "            self.hparams.num_classes = self.args.num_classes\n",
    "            self.hparams.num_training_steps = self.args.num_training_steps\n",
    "            self.hparams.warmup_steps = self.args.warmup_steps\n",
    "            self.hparams.emb_len = self.args.emb_len\n",
    "            self.hparams.max_seq_length = self.args.max_seq_length\n",
    "            self.hparams.hidden_dim = self.args.hidden_dim\n",
    "            self.hparams.dropout = self.args.dropout\n",
    "            self.hparams.nb_epochs = self.args.nb_epochs\n",
    "            self.hparams.temp = self.args.temp\n",
    "            self.hparams.coefficient = self.args.coefficient\n",
    "            self.hparams.num_hard_negatives = self.args.num_hard_negatives\n",
    "            self.hparams.loss1_type = self.args.loss1_type\n",
    "            self.hparams.loss2_type = self.args.loss2_type\n",
    "            self.hparams.pooling = self.args.pooling\n",
    "            self.hparams.num_triplets_per_sample = self.args.nb_triplets\n",
    "        \n",
    "        # freeze\n",
    "        self._frozen = False\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Loading model\n",
    "        self.model = AutoModel.from_pretrained(self.hparams.model_name_or_path)\n",
    "        \n",
    "        if self.hparams.pooling == True:\n",
    "            self.model = DeclutrClassifier(self.model, LogisticRegression(self.hparams.emb_len, \n",
    "                                                                          self.hparams.hidden_dim, self.hparams.num_classes, \n",
    "                                                                          dropout=self.hparams.dropout))\n",
    "        else:\n",
    "             self.model = DeclutrClassifier(self.model, LogisticRegression(self.hparams.emb_len * self.hparams.max_seq_length, \n",
    "                                                                      self.hparams.hidden_dim, self.hparams.num_classes, \n",
    "                                                                      dropout=self.hparams.dropout))\n",
    "        # self.model = nn.DataParallel(self.model).cuda()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids, token_ids, attention_mask, y = batch\n",
    "        x, y = (input_ids, token_ids, attention_mask), y\n",
    "        \n",
    "        pred, _, feats = self.model(x, self.hparams.pooling, return_feat=True)\n",
    "        \n",
    "        if self.hparams.loss1_type == \"CE\":\n",
    "            loss_1 = self.criterion(pred, y.long())\n",
    "        else:\n",
    "            loss_1 = 0\n",
    "            self.hparams.coefficient = 1\n",
    "\n",
    "        if self.hparams.loss2_type == \"KL\":\n",
    "            mask = y.clone().cpu().apply_(lambda x: x not in []).type(torch.bool)\n",
    "            feats, pred, y = feats[mask], pred[mask], y[mask]\n",
    "\n",
    "            sim_matrix = compute_sim_matrix(feats)\n",
    "            target_matrix = compute_target_matrix(y)\n",
    "            loss_contrastive = kl_contrastive_loss(sim_matrix, target_matrix, self.hparams.temp, y)\n",
    "\n",
    "        elif self.hparams.loss2_type == \"infoNCE-negatives\":\n",
    "            loss_contrastive = supervised_infoNCE_loss_with_negatives(feats, y, self.hparams.temp)\n",
    "\n",
    "        elif self.hparams.loss2_type == \"SupCon-negatives\":\n",
    "            loss_contrastive = supervised_contrastive_loss_with_negatives(feats, y, self.hparams.temp)\n",
    "\n",
    "        elif self.hparams.loss2_type == \"triplet\":\n",
    "            triplet_loss, _ = compute_triplet_loss(feats, y, self.hparams.num_triplets_per_sample)\n",
    "            loss_contrastive = triplet_loss\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Loss2 type can only be between KL, infoNCE, infoNCE-negatives (with in-batch negatives), SupCon, triplet, and SupCon-negatives (with in-batch negatives). Other losses have not been implemented.\")\n",
    "        \n",
    "        total_loss = loss_1 + self.hparams.coefficient * loss_contrastive\n",
    "        \n",
    "        return pred, feats, y, total_loss\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class stipulates you to overwrite. This we do here, by virtue of this definition\n",
    "        _, _, _, train_loss = self(batch)  # self refers to the model, which in turn acceses the forward method\n",
    "        self.log_dict({\"train_loss\": train_loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return train_loss\n",
    "        # the training_step method expects a dictionary, which should at least contain the loss\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class  wants you to overwrite, in case you want to do validation. This we do here, by virtue of this definition.\n",
    "\n",
    "        pred, _, y, val_loss = self(batch)\n",
    "        # self refers to the model, which in turn accesses the forward method\n",
    "\n",
    "        # Evaluating the performance\n",
    "        predictions = torch.argmax(pred, dim=1)\n",
    "        balanced_accuracy = balanced_accuracy_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), adjusted=True)\n",
    "        macro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='macro')\n",
    "        micro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='micro')\n",
    "        weighted_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='weighted')        \n",
    "        \n",
    "        self.log_dict({\"val_loss\": val_loss, 'accuracy': balanced_accuracy, 'macro-F1': macro_accuracy, 'micro-F1': micro_accuracy, 'weighted-F1':weighted_accuracy}, \n",
    "                       on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        \n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class  wants you to overwrite, in case you want to do test. This we do here, by virtue of this definition.\n",
    "\n",
    "        pred, _, y, test_loss = self(batch)\n",
    "        # self refers to the model, which in turn accesses the forward method\n",
    "\n",
    "        # Evaluating the performance\n",
    "        predictions = torch.argmax(pred, dim=1)\n",
    "        balanced_accuracy = balanced_accuracy_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), adjusted=True)\n",
    "        macro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='macro')\n",
    "        micro_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='micro')\n",
    "        weighted_accuracy = f1_score(y.detach().cpu().numpy(), predictions.detach().cpu().numpy(), average='weighted')\n",
    "        \n",
    "        self.log_dict({\"test_loss\": test_loss, 'accuracy': balanced_accuracy, 'macro-F1': macro_accuracy, 'micro-F1': micro_accuracy, 'weighted-F1':weighted_accuracy}, \n",
    "                      on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return test_loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_nb):\n",
    "        # the training step is a (virtual) method,specified in the interface, that the pl.LightningModule\n",
    "        # class  wants you to overwrite, in case you want to do validation. This we do here, by virtue of this definition.\n",
    "        return None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # The configure_optimizers is a (virtual) method, specified in the interface, that the\n",
    "        # pl.LightningModule class wants you to overwrite.\n",
    "\n",
    "        # In this case we define that some parameters are optimized in a different way than others. In\n",
    "        # particular we single out parameters that have 'bias', 'LayerNorm.weight' in their names. For those\n",
    "        # we do not use an optimization technique called weight decay.\n",
    "\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "        optimizer_grouped_parameters = [{'params': [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay':self.hparams.weight_decay}, \n",
    "                                        {'params': [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.eps)\n",
    "        # optimizer = DeepSpeedCPUAdam(optimizer_grouped_parameters, adamw_mode=True, lr=self.hparams.learning_rate, betas=(0.9, 0.999), eps=self.hparams.eps)\n",
    "\n",
    "        # We also use a scheduler that is supplied by transformers.\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.hparams.num_training_steps)\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.nb_epochs)\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def freeze(self) -> None:\n",
    "        # freeze all layers, except the final classifier layers\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'classifier' not in name:  # classifier layer\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self._frozen = True\n",
    "\n",
    "    def unfreeze(self) -> None:\n",
    "        if self._frozen:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if 'classifier' not in name:  # classifier layer\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        self._frozen = False\n",
    "\n",
    "    def train_epoch_start(self):\n",
    "        \"\"\"pytorch lightning hook\"\"\"\n",
    "        if self.current_epoch < self.hparams.nr_frozen_epochs:\n",
    "            self.freeze()\n",
    "\n",
    "        if self.current_epoch >= self.hparams.nr_frozen_epochs:\n",
    "            self.unfreeze() \n",
    "\n",
    "\n",
    "class SemiConstrativeModel(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        if isinstance(args, tuple) and len(args) > 0: \n",
    "            self.args = args[0]\n",
    "            self.hparams.learning_rate = self.args.learning_rate\n",
    "            self.hparams.eps = self.args.adam_epsilon\n",
    "            self.hparams.weight_decay = self.args.weight_decay\n",
    "            self.hparams.model_name_or_path = self.args.model_name_or_path\n",
    "            self.hparams.num_classes = self.args.num_classes\n",
    "            self.hparams.num_training_steps = self.args.num_training_steps\n",
    "            self.hparams.warmup_steps = self.args.warmup_steps\n",
    "            self.hparams.emb_len = self.args.emb_len\n",
    "            self.hparams.max_seq_length = self.args.max_seq_length\n",
    "            self.hparams.hidden_dim = self.args.hidden_dim\n",
    "            self.hparams.dropout = self.args.dropout\n",
    "            self.hparams.nb_epochs = self.args.nb_epochs\n",
    "            self.hparams.temp = self.args.temp\n",
    "            self.hparams.coefficient = self.args.coefficient\n",
    "            self.hparams.num_hard_negatives = self.args.num_hard_negatives\n",
    "            self.hparams.loss_type = self.args.loss_type\n",
    "            self.hparams.pooling = self.args.pooling\n",
    "            self.hparams.num_triplets_per_sample = self.args.nb_triplets\n",
    "        \n",
    "        # freeze\n",
    "        self._frozen = False\n",
    "        \n",
    "        # Loading model\n",
    "        self.model = AutoModel.from_pretrained(self.hparams.model_name_or_path)\n",
    "        \n",
    "        # No classification layer\n",
    "        if self.hparams.pooling == True:\n",
    "            self.model = DeclutrClassifier(self.model, nn.Identity())\n",
    "        else:\n",
    "            self.model = DeclutrClassifier(self.model, nn.Identity())\n",
    "\n",
    "    def forward(self, batch, compute_loss=True):\n",
    "        input_ids, token_ids, attention_mask, y = batch\n",
    "        x, y = (input_ids, token_ids, attention_mask), y\n",
    "\n",
    "        # Extract features (embeddings) from the model\n",
    "        feats, _, _ = self.model(x, self.hparams.pooling, return_feat=True)\n",
    "\n",
    "        # During inference, skip loss computation\n",
    "        if not self.training or not compute_loss:\n",
    "            return feats, y\n",
    "\n",
    "        # Compute the loss only during training\n",
    "        if self.hparams.loss_type == \"SupCon\":\n",
    "            loss_contrastive = supervised_contrastive_loss_with_negatives(feats, y, self.hparams.temp)\n",
    "        elif self.hparams.loss_type == \"triplet\":\n",
    "            loss_contrastive, _ = compute_triplet_loss(feats, y, self.hparams.num_triplets_per_sample)\n",
    "        else:\n",
    "            raise Exception(\"Loss type can only be between SupCon and triplet, both with in-batch negatives. Other losses have not been implemented.\")\n",
    "\n",
    "        total_loss = self.hparams.coefficient * loss_contrastive\n",
    "\n",
    "        return feats, y, total_loss\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        _, _, train_loss = self(batch)\n",
    "        self.log_dict({\"train_loss\": train_loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        _, _, val_loss = self(batch)\n",
    "        # No classification accuracy metrics needed for contrastive learning\n",
    "        self.log_dict({\"val_loss\": val_loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        _, _, test_loss = self(batch)\n",
    "        self.log_dict({\"test_loss\": test_loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return test_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [{'params': [p for n, p in self.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay':self.hparams.weight_decay}, \n",
    "                                        {'params': [p for n, p in self.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
    "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.eps)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.hparams.num_training_steps)\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def generate_embeddings(self, batch):\n",
    "        \"\"\"\n",
    "        Function to generate embeddings for inference.\n",
    "        Args:\n",
    "            batch: Input batch containing tokenized inputs (input_ids, token_type_ids, attention_mask)\n",
    "        Returns:\n",
    "            feats: Generated embeddings\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            input_ids, token_ids, attention_mask, _ = batch\n",
    "            x = (input_ids, token_ids, attention_mask)\n",
    "            feats, _, _  = self.model(x, self.hparams.pooling, return_feat=True)\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fbf32-b31b-406b-9150-0a98f690a284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Loading the Classifier model\n",
    "model = HTContraClassifierModel.load_from_checkpoint(\"/workspace/persistent/HTClipper/models/grouped-and-masked/text-baselines/contra-learn/triplet-loss/declutr-small/south/pooled/seed:1111/lr-0.0001/coeff-1.0/temp:0.1/triplet/final_model.ckpt\").eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d68a4ed-e571-4623-997b-a44f529e7acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3842e8-74f8-4681-a738-f047b3acb31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Loading the Metric learning model\n",
    "model = SemiConstrativeModel.load_from_checkpoint(\"/workspace/persistent/HTClipper/models/grouped-and-masked/text-baselines/contra-learn/semi-supervised/declutr-small/south/pooled/seed:1111/lr-0.0001/coeff-1.0/temp:0.1/SupCon/final_model.ckpt\").eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bba313-21ca-4ba2-b97a-a9416d70409a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extracting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62f2f94-5744-4425-8245-c487e61f4417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chicago_df = pd.read_csv(\"../data/processed/chicago.csv\")\n",
    "atlanta_df = pd.read_csv(\"../data/processed/atlanta.csv\")\n",
    "dallas_df = pd.read_csv(\"../data/processed/dallas.csv\")\n",
    "detroit_df = pd.read_csv(\"../data/processed/detroit.csv\")\n",
    "houston_df = pd.read_csv(\"../data/processed/houston.csv\")\n",
    "ny_df = pd.read_csv(\"../data/processed/ny.csv\")\n",
    "sf_df = pd.read_csv(\"../data/processed/sf.csv\")\n",
    "canada_df = pd.read_csv(\"../data/processed/canada.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f86a2258-0d1b-4fb4-b154-21e5adfcc29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "south_df = pd.read_csv(\"../data/processed/south.csv\")\n",
    "midwest_df = pd.read_csv(\"../data/processed/midwest.csv\")\n",
    "west_df = pd.read_csv(\"../data/processed/west.csv\")\n",
    "northeast_df = pd.read_csv(\"../data/processed/northeast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "78ce22a7-3014-4551-84e0-cb3e3b72f0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87e74514-2558-495a-aa21-7303dcac09be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_embedding_of_trained_checkpoints(df, model, tokenizer, city, model_name):\n",
    "    df = df[[\"TEXT\", \"VENDOR\"]].drop_duplicates()\n",
    "    \n",
    "    # Since the vendor IDs are not the current representations of the class labels, we remap these label IDs to avoid falling into out-of-bounds problem\n",
    "    vendors_dict = {}\n",
    "    i = 0\n",
    "    for vendor in df.VENDOR.values.tolist():\n",
    "        if vendor not in vendors_dict.keys():\n",
    "            vendors_dict[vendor] = i\n",
    "            i += 1\n",
    "\n",
    "    df.replace({\"VENDOR\": vendors_dict}, inplace=True)\n",
    "    train_df, test_df = train_test_split(df, test_size=0.20, random_state=1111)\n",
    "    \n",
    "    embeddings, labels = extract_embeddings(train_df, model, vendors_dict)\n",
    "    \n",
    "    directory = os.path.join(os.getcwd(), \"../models/pickled/embeddings/grouped-and-masked\", \"trained_\" + model_name + \"_all\")\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    label_filename = city + \"_labels_train.pt\"\n",
    "    data_filename = city + \"_data_train.pt\"\n",
    "    torch.save(embeddings, os.path.join(directory, data_filename))\n",
    "    torch.save(labels, os.path.join(directory, label_filename))\n",
    "\n",
    "    embeddings, labels = extract_embeddings(test_df, model, vendors_dict)\n",
    "    label_filename = city + \"_labels_test.pt\"\n",
    "    data_filename = city + \"_data_test.pt\"\n",
    "    torch.save(embeddings, os.path.join(directory, data_filename))\n",
    "    torch.save(labels, os.path.join(directory, label_filename))\n",
    "\n",
    "def extract_embeddings(df, model, vendors_dict, device=\"cuda\", pooling_type=\"mean\"):\n",
    "    text = df.TEXT.values.tolist()\n",
    "    vendors = df.VENDOR.values.tolist()\n",
    "\n",
    "    # Tokenizing the data with padding and truncation\n",
    "    encodings = tokenizer(text, add_special_tokens=True, max_length=512, padding='max_length', return_token_type_ids=True, truncation=True, \n",
    "                               return_attention_mask=True, return_tensors='pt') \n",
    "\n",
    "\n",
    "    # Move the encodings to the device\n",
    "    input_ids = encodings['input_ids'].to(device)\n",
    "    token_ids = encodings['token_type_ids'].to(device)\n",
    "    attention_mask = encodings['attention_mask'].to(device)\n",
    "    labels = torch.tensor(vendors).to(device)\n",
    "\n",
    "    # Combine the inputs into a TensorDataset.\n",
    "    dataset = TensorDataset(input_ids, token_ids, attention_mask, labels)\n",
    "    test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    pooled_output_list, labels_list = [], []\n",
    "    pbar = tqdm(total=len(test_dataloader))\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            \n",
    "            # Uncomment this line if you want to generate representation for the classification model\n",
    "            # _, feats, y, _ = model(batch)\n",
    "            # And comment the one below\n",
    "            feats, y= model(batch, compute_loss=False)\n",
    "            \n",
    "            pooled_output_list.append(feats)\n",
    "            labels_list.append(y)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    # Concatenate the pooled outputs and labels into tensors\n",
    "    pooled_outputs = torch.cat(pooled_output_list)\n",
    "    labels = torch.cat(labels_list)\n",
    "    return pooled_outputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "50ad1b17-7f63-4c21-84a5-c7042b85736a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/353 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|         | 10/353 [00:00<00:03, 91.85it/s]\u001b[A\n",
      "  6%|         | 20/353 [00:00<00:06, 54.10it/s]\u001b[A\n",
      "  8%|         | 27/353 [00:00<00:06, 48.88it/s]\u001b[A\n",
      "  9%|         | 33/353 [00:00<00:06, 46.50it/s]\u001b[A\n",
      " 11%|         | 38/353 [00:00<00:06, 45.17it/s]\u001b[A\n",
      " 12%|        | 43/353 [00:00<00:07, 44.24it/s]\u001b[A\n",
      " 14%|        | 48/353 [00:01<00:07, 43.57it/s]\u001b[A\n",
      " 15%|        | 53/353 [00:01<00:06, 43.09it/s]\u001b[A\n",
      " 16%|        | 58/353 [00:01<00:06, 42.76it/s]\u001b[A\n",
      " 18%|        | 63/353 [00:01<00:06, 42.51it/s]\u001b[A\n",
      " 19%|        | 68/353 [00:01<00:06, 42.33it/s]\u001b[A\n",
      " 21%|        | 73/353 [00:01<00:06, 42.20it/s]\u001b[A\n",
      " 22%|       | 78/353 [00:01<00:06, 42.12it/s]\u001b[A\n",
      " 24%|       | 83/353 [00:01<00:06, 42.07it/s]\u001b[A\n",
      " 25%|       | 88/353 [00:01<00:06, 42.03it/s]\u001b[A\n",
      " 26%|       | 93/353 [00:02<00:06, 42.01it/s]\u001b[A\n",
      " 28%|       | 98/353 [00:02<00:06, 41.99it/s]\u001b[A\n",
      " 29%|       | 103/353 [00:02<00:05, 41.98it/s]\u001b[A\n",
      " 31%|       | 108/353 [00:02<00:05, 41.95it/s]\u001b[A\n",
      " 32%|      | 113/353 [00:02<00:05, 41.94it/s]\u001b[A\n",
      " 33%|      | 118/353 [00:02<00:05, 41.92it/s]\u001b[A\n",
      " 35%|      | 123/353 [00:02<00:05, 41.92it/s]\u001b[A\n",
      " 36%|      | 128/353 [00:02<00:05, 41.93it/s]\u001b[A\n",
      " 38%|      | 133/353 [00:03<00:05, 41.90it/s]\u001b[A\n",
      " 39%|      | 138/353 [00:03<00:05, 41.87it/s]\u001b[A\n",
      " 41%|      | 143/353 [00:03<00:05, 41.88it/s]\u001b[A\n",
      " 42%|     | 148/353 [00:03<00:04, 41.88it/s]\u001b[A\n",
      " 43%|     | 153/353 [00:03<00:04, 41.89it/s]\u001b[A\n",
      " 45%|     | 158/353 [00:03<00:04, 41.89it/s]\u001b[A\n",
      " 46%|     | 163/353 [00:03<00:04, 41.91it/s]\u001b[A\n",
      " 48%|     | 168/353 [00:03<00:04, 41.92it/s]\u001b[A\n",
      " 49%|     | 173/353 [00:03<00:04, 41.90it/s]\u001b[A\n",
      " 50%|     | 178/353 [00:04<00:04, 41.90it/s]\u001b[A\n",
      " 52%|    | 183/353 [00:04<00:04, 41.86it/s]\u001b[A\n",
      " 53%|    | 188/353 [00:04<00:03, 41.87it/s]\u001b[A\n",
      " 55%|    | 193/353 [00:04<00:03, 41.89it/s]\u001b[A\n",
      " 56%|    | 198/353 [00:04<00:03, 41.89it/s]\u001b[A\n",
      " 58%|    | 203/353 [00:04<00:03, 41.90it/s]\u001b[A\n",
      " 59%|    | 208/353 [00:04<00:03, 41.86it/s]\u001b[A\n",
      " 60%|    | 213/353 [00:04<00:03, 41.86it/s]\u001b[A\n",
      " 62%|   | 218/353 [00:05<00:03, 41.87it/s]\u001b[A\n",
      " 63%|   | 223/353 [00:05<00:03, 41.86it/s]\u001b[A\n",
      " 65%|   | 228/353 [00:05<00:02, 41.86it/s]\u001b[A\n",
      " 66%|   | 233/353 [00:05<00:02, 41.87it/s]\u001b[A\n",
      " 67%|   | 238/353 [00:05<00:02, 41.88it/s]\u001b[A\n",
      " 69%|   | 243/353 [00:05<00:02, 41.87it/s]\u001b[A\n",
      " 70%|   | 248/353 [00:05<00:02, 41.85it/s]\u001b[A\n",
      " 72%|  | 253/353 [00:05<00:02, 41.84it/s]\u001b[A\n",
      " 73%|  | 258/353 [00:06<00:02, 41.82it/s]\u001b[A\n",
      " 75%|  | 263/353 [00:06<00:02, 41.84it/s]\u001b[A\n",
      " 76%|  | 268/353 [00:06<00:02, 41.85it/s]\u001b[A\n",
      " 77%|  | 273/353 [00:06<00:01, 41.84it/s]\u001b[A\n",
      " 79%|  | 278/353 [00:06<00:01, 41.83it/s]\u001b[A\n",
      " 80%|  | 283/353 [00:06<00:01, 41.84it/s]\u001b[A\n",
      " 82%| | 288/353 [00:06<00:01, 41.84it/s]\u001b[A\n",
      " 83%| | 293/353 [00:06<00:01, 41.83it/s]\u001b[A\n",
      " 84%| | 298/353 [00:06<00:01, 41.83it/s]\u001b[A\n",
      " 86%| | 303/353 [00:07<00:01, 41.81it/s]\u001b[A\n",
      " 87%| | 308/353 [00:07<00:01, 41.83it/s]\u001b[A\n",
      " 89%| | 313/353 [00:07<00:00, 41.84it/s]\u001b[A\n",
      " 90%| | 318/353 [00:07<00:00, 41.84it/s]\u001b[A\n",
      " 92%|| 323/353 [00:07<00:00, 41.84it/s]\u001b[A\n",
      " 93%|| 328/353 [00:07<00:00, 41.85it/s]\u001b[A\n",
      " 94%|| 333/353 [00:07<00:00, 41.85it/s]\u001b[A\n",
      " 96%|| 338/353 [00:07<00:00, 41.85it/s]\u001b[A\n",
      " 97%|| 343/353 [00:08<00:00, 41.83it/s]\u001b[A\n",
      " 99%|| 348/353 [00:08<00:00, 41.84it/s]\u001b[A\n",
      "100%|| 353/353 [00:08<00:00, 42.56it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/89 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|         | 10/89 [00:00<00:00, 91.68it/s]\u001b[A\n",
      " 22%|       | 20/89 [00:00<00:01, 54.00it/s]\u001b[A\n",
      " 30%|       | 27/89 [00:00<00:01, 48.78it/s]\u001b[A\n",
      " 37%|      | 33/89 [00:00<00:01, 46.37it/s]\u001b[A\n",
      " 43%|     | 38/89 [00:00<00:01, 45.07it/s]\u001b[A\n",
      " 48%|     | 43/89 [00:00<00:01, 44.13it/s]\u001b[A\n",
      " 54%|    | 48/89 [00:01<00:00, 43.45it/s]\u001b[A\n",
      " 60%|    | 53/89 [00:01<00:00, 42.99it/s]\u001b[A\n",
      " 65%|   | 58/89 [00:01<00:00, 42.66it/s]\u001b[A\n",
      " 71%|   | 63/89 [00:01<00:00, 42.40it/s]\u001b[A\n",
      " 76%|  | 68/89 [00:01<00:00, 42.23it/s]\u001b[A\n",
      " 82%| | 73/89 [00:01<00:00, 42.10it/s]\u001b[A\n",
      " 88%| | 78/89 [00:01<00:00, 42.01it/s]\u001b[A\n",
      " 93%|| 83/89 [00:01<00:00, 41.95it/s]\u001b[A\n",
      "100%|| 89/89 [00:01<00:00, 44.69it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/215 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|         | 10/215 [00:00<00:02, 91.25it/s]\u001b[A\n",
      "  9%|         | 20/215 [00:00<00:03, 53.89it/s]\u001b[A\n",
      " 13%|        | 27/215 [00:00<00:03, 48.66it/s]\u001b[A\n",
      " 15%|        | 33/215 [00:00<00:03, 46.28it/s]\u001b[A\n",
      " 18%|        | 38/215 [00:00<00:03, 44.98it/s]\u001b[A\n",
      " 20%|        | 43/215 [00:00<00:03, 44.07it/s]\u001b[A\n",
      " 22%|       | 48/215 [00:01<00:03, 43.42it/s]\u001b[A\n",
      " 25%|       | 53/215 [00:01<00:03, 42.94it/s]\u001b[A\n",
      " 27%|       | 58/215 [00:01<00:03, 42.60it/s]\u001b[A\n",
      " 29%|       | 63/215 [00:01<00:03, 42.35it/s]\u001b[A\n",
      " 32%|      | 68/215 [00:01<00:03, 42.18it/s]\u001b[A\n",
      " 34%|      | 73/215 [00:01<00:03, 42.06it/s]\u001b[A\n",
      " 36%|      | 78/215 [00:01<00:03, 42.00it/s]\u001b[A\n",
      " 39%|      | 83/215 [00:01<00:03, 41.92it/s]\u001b[A\n",
      " 41%|      | 88/215 [00:01<00:03, 41.86it/s]\u001b[A\n",
      " 43%|     | 93/215 [00:02<00:02, 41.84it/s]\u001b[A\n",
      " 46%|     | 98/215 [00:02<00:02, 41.81it/s]\u001b[A\n",
      " 48%|     | 103/215 [00:02<00:02, 41.82it/s]\u001b[A\n",
      " 50%|     | 108/215 [00:02<00:02, 41.80it/s]\u001b[A\n",
      " 53%|    | 113/215 [00:02<00:02, 41.80it/s]\u001b[A\n",
      " 55%|    | 118/215 [00:02<00:02, 41.81it/s]\u001b[A\n",
      " 57%|    | 123/215 [00:02<00:02, 41.82it/s]\u001b[A\n",
      " 60%|    | 128/215 [00:02<00:02, 41.80it/s]\u001b[A\n",
      " 62%|   | 133/215 [00:03<00:01, 41.80it/s]\u001b[A\n",
      " 64%|   | 138/215 [00:03<00:01, 41.81it/s]\u001b[A\n",
      " 67%|   | 143/215 [00:03<00:01, 41.80it/s]\u001b[A\n",
      " 69%|   | 148/215 [00:03<00:01, 41.80it/s]\u001b[A\n",
      " 71%|   | 153/215 [00:03<00:01, 41.82it/s]\u001b[A\n",
      " 73%|  | 158/215 [00:03<00:01, 41.82it/s]\u001b[A\n",
      " 76%|  | 163/215 [00:03<00:01, 41.80it/s]\u001b[A\n",
      " 78%|  | 168/215 [00:03<00:01, 41.80it/s]\u001b[A\n",
      " 80%|  | 173/215 [00:04<00:01, 41.77it/s]\u001b[A\n",
      " 83%| | 178/215 [00:04<00:00, 41.77it/s]\u001b[A\n",
      " 85%| | 183/215 [00:04<00:00, 41.77it/s]\u001b[A\n",
      " 87%| | 188/215 [00:04<00:00, 41.78it/s]\u001b[A\n",
      " 90%| | 193/215 [00:04<00:00, 41.79it/s]\u001b[A\n",
      " 92%|| 198/215 [00:04<00:00, 41.77it/s]\u001b[A\n",
      " 94%|| 203/215 [00:04<00:00, 41.78it/s]\u001b[A\n",
      " 97%|| 208/215 [00:04<00:00, 41.78it/s]\u001b[A\n",
      "100%|| 215/215 [00:05<00:00, 42.92it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      " 19%|        | 10/54 [00:00<00:00, 91.38it/s]\u001b[A\n",
      " 37%|      | 20/54 [00:00<00:00, 53.79it/s]\u001b[A\n",
      " 50%|     | 27/54 [00:00<00:00, 48.64it/s]\u001b[A\n",
      " 61%|    | 33/54 [00:00<00:00, 46.27it/s]\u001b[A\n",
      " 70%|   | 38/54 [00:00<00:00, 44.93it/s]\u001b[A\n",
      " 80%|  | 43/54 [00:00<00:00, 44.00it/s]\u001b[A\n",
      " 89%| | 48/54 [00:01<00:00, 43.34it/s]\u001b[A\n",
      "100%|| 54/54 [00:01<00:00, 46.44it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/82 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|        | 10/82 [00:00<00:00, 91.33it/s]\u001b[A\n",
      " 24%|       | 20/82 [00:00<00:01, 53.79it/s]\u001b[A\n",
      " 33%|      | 27/82 [00:00<00:01, 48.57it/s]\u001b[A\n",
      " 40%|      | 33/82 [00:00<00:01, 46.20it/s]\u001b[A\n",
      " 46%|     | 38/82 [00:00<00:00, 44.88it/s]\u001b[A\n",
      " 52%|    | 43/82 [00:00<00:00, 43.94it/s]\u001b[A\n",
      " 59%|    | 48/82 [00:01<00:00, 43.26it/s]\u001b[A\n",
      " 65%|   | 53/82 [00:01<00:00, 42.78it/s]\u001b[A\n",
      " 71%|   | 58/82 [00:01<00:00, 42.47it/s]\u001b[A\n",
      " 77%|  | 63/82 [00:01<00:00, 42.25it/s]\u001b[A\n",
      " 83%| | 68/82 [00:01<00:00, 42.07it/s]\u001b[A\n",
      " 89%| | 73/82 [00:01<00:00, 41.95it/s]\u001b[A\n",
      "100%|| 82/82 [00:01<00:00, 44.66it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      " 48%|     | 10/21 [00:00<00:00, 91.54it/s]\u001b[A\n",
      "100%|| 21/21 [00:00<00:00, 56.30it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/65 [00:00<?, ?it/s]\u001b[A\n",
      " 15%|        | 10/65 [00:00<00:00, 91.47it/s]\u001b[A\n",
      " 31%|       | 20/65 [00:00<00:00, 53.73it/s]\u001b[A\n",
      " 42%|     | 27/65 [00:00<00:00, 48.53it/s]\u001b[A\n",
      " 51%|     | 33/65 [00:00<00:00, 46.15it/s]\u001b[A\n",
      " 58%|    | 38/65 [00:00<00:00, 44.86it/s]\u001b[A\n",
      " 66%|   | 43/65 [00:00<00:00, 43.94it/s]\u001b[A\n",
      " 74%|  | 48/65 [00:01<00:00, 43.26it/s]\u001b[A\n",
      " 82%| | 53/65 [00:01<00:00, 42.79it/s]\u001b[A\n",
      " 89%| | 58/65 [00:01<00:00, 42.46it/s]\u001b[A\n",
      "100%|| 65/65 [00:01<00:00, 45.49it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\n",
      "100%|| 17/17 [00:00<00:00, 62.21it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "extract_embedding_of_trained_checkpoints(south_df, model, tokenizer, city=\"south\", model_name=\"declutr_SupCononly_all\")\n",
    "extract_embedding_of_trained_checkpoints(midwest_df, model, tokenizer, city=\"midwest\", model_name=\"declutr_SupCononly_all\")\n",
    "extract_embedding_of_trained_checkpoints(west_df, model, tokenizer, city=\"west\", model_name=\"declutr_SupCononly_all\")\n",
    "extract_embedding_of_trained_checkpoints(northeast_df, model, tokenizer, city=\"northeast\", model_name=\"declutr_SupCononly_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed101c-27ee-49ef-9e09-4d19fac5e22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c0c01-79e5-4894-8682-31978ef52f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HT",
   "language": "python",
   "name": "ht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
