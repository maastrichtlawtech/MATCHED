{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963d588e-1886-468e-9ac9-f2e21f443c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108d5e18-97fd-436d-909f-888c5f54cf88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embeddings(model_name, city):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if model_name == \"declutr\":\n",
    "        emb_dir = \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/pretrained_declutr/\"\n",
    "        train_label_filename = \"pretrained_checkpoint_\" + model_name + \"_\" + city + \"_labels_train.pt\"\n",
    "        train_data_filename = \"pretrained_checkpoint_\" + model_name  + \"_\" + city + \"_data_train.pt\"\n",
    "        test_label_filename = \"pretrained_checkpoint_\" + model_name + \"_\" + city + \"_labels_test.pt\"\n",
    "        test_data_filename = \"pretrained_checkpoint_\" + model_name  + \"_\" + city + \"_data_test.pt\"\n",
    "    else:\n",
    "        emb_dir = \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/pretrained_vit_patch16/\"\n",
    "        train_label_filename = \"pretrained_vit_patch16_\" + city + \"_all_train_labels.pt\"\n",
    "        train_data_filename = \"pretrained_vit_patch16_\" + city + \"_all_train_embeddings.pt\"\n",
    "        test_label_filename = \"pretrained_vit_patch16_\" + city + \"_all_test_labels.pt\"\n",
    "        test_data_filename = \"pretrained_vit_patch16_\" + city + \"_all_test_embeddings.pt\"\n",
    "    \n",
    "    train_emb = torch.load(os.path.join(emb_dir, train_data_filename), map_location=device)\n",
    "    # train_labels = torch.load(os.path.join(emb_dir, train_label_filename), map_location=device)\n",
    "    \n",
    "    test_emb = torch.load(os.path.join(emb_dir, test_data_filename), map_location=device)\n",
    "    # test_labels = torch.load(os.path.join(emb_dir, test_label_filename), map_location=device)\n",
    "    \n",
    "    embeddings = torch.cat((torch.from_numpy(train_emb), torch.from_numpy(test_emb)), dim=0)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f763187d-321b-4e6e-994c-d2c6a0bc946e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(embeddings1, embeddings2, batch_size=512):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two sets of embeddings in a batched manner.\n",
    "    Args:\n",
    "    - embeddings1, embeddings2: Tensors containing embeddings (size [N, d] and [M, d]).\n",
    "    - batch_size: Size of the batch for batched similarity calculation.\n",
    "\n",
    "    Returns:\n",
    "    - similarity_matrix: Tensor of cosine similarities of size [N, M].\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    # Outer loop over embeddings1 with tqdm\n",
    "    for i in tqdm(range(0, embeddings1.size(0), batch_size), desc=\"Processing embeddings1 batches\"):\n",
    "        batch1 = embeddings1[i:i + batch_size]\n",
    "        \n",
    "        # Inner loop over embeddings2 with tqdm\n",
    "        batch_similarities = []\n",
    "        for j in range(0, embeddings2.size(0), batch_size):\n",
    "            batch2 = embeddings2[j:j + batch_size]\n",
    "            # Compute similarity and store\n",
    "            sim = cosine_similarity(batch1.unsqueeze(1), batch2.unsqueeze(0), dim=2)\n",
    "            batch_similarities.append(sim)\n",
    "        \n",
    "        # Concatenate along columns for the current batch of embeddings1\n",
    "        similarities.append(torch.cat(batch_similarities, dim=1))\n",
    "    \n",
    "    # Concatenate all batches along rows to form the full similarity matrix\n",
    "    similarity_matrix = torch.cat(similarities, dim=0)\n",
    "    return similarity_matrix.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e791d-62b6-43e9-9cd1-223d4ac323a9",
   "metadata": {},
   "source": [
    "# Declutr-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99e41b29-8078-4417-b906-0c5ad48a2c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"South\": load_embeddings(\"declutr\", \"south\"),\n",
    "    \"West\": load_embeddings(\"declutr\", \"west\"),\n",
    "    \"Northeast\": load_embeddings(\"declutr\", \"northeast\"),\n",
    "    \"Midwest\": load_embeddings(\"declutr\", \"midwest\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7bdd4b7d-0c86-422f-ad51-07e0e45002b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate similarity between two embeddings\n",
    "def calculate_average_similarity(embeddings1, embeddings2, batch_size=512):\n",
    "    similarities = []\n",
    "    for i in tqdm(range(0, embeddings1.size(0), batch_size), desc=\"Processing batch\"):\n",
    "        batch1 = embeddings1[i:i + batch_size]\n",
    "        batch_similarities = []\n",
    "        for j in range(0, embeddings2.size(0), batch_size):\n",
    "            batch2 = embeddings2[j:j + batch_size]\n",
    "            sim = cosine_similarity(batch1.unsqueeze(1), batch2.unsqueeze(0), dim=2)\n",
    "            batch_similarities.append(sim.mean().item())  # Compute mean similarity for this sub-batch\n",
    "        similarities.append(np.mean(batch_similarities))  # Average sub-batch similarities\n",
    "    return np.mean(similarities)  # Final average similarity for the entire batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e94be3d2-d582-4bf4-9430-485ee99724fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 28/28 [00:52<00:00,  1.87s/it]\n",
      "Processing batch: 100%|██████████| 28/28 [00:42<00:00,  1.52s/it]\n",
      "Processing batch: 100%|██████████| 28/28 [02:16<00:00,  4.89s/it]\n",
      "Processing batch: 100%|██████████| 7/7 [00:09<00:00,  1.37s/it]\n",
      "Processing batch: 100%|██████████| 7/7 [00:31<00:00,  4.54s/it]\n",
      "Processing batch: 100%|██████████| 6/6 [00:25<00:00,  4.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store similarities\n",
    "similarity_matrix = {}\n",
    "regions = list(datasets.keys())\n",
    "\n",
    "for i, region1 in enumerate(regions):\n",
    "    if region1 not in similarity_matrix:\n",
    "        similarity_matrix[region1] = {}  # Initialize the inner dictionary\n",
    "    for j, region2 in enumerate(regions):\n",
    "        if region2 not in similarity_matrix:\n",
    "            similarity_matrix[region2] = {}  # Ensure initialization for the symmetric entry\n",
    "        if i == j:\n",
    "            similarity_matrix[region1][region2] = 1.0  # Similarity with itself\n",
    "        elif j > i:  # Avoid redundant calculations\n",
    "            similarity = calculate_average_similarity(datasets[region1], datasets[region2])\n",
    "            similarity_matrix[region1][region2] = similarity\n",
    "            similarity_matrix[region2][region1] = similarity  # Symmetric matrix\n",
    "\n",
    "# Convert dictionary to a 2D numpy array for heatmap\n",
    "matrix = np.array([[similarity_matrix[region1][region2] for region2 in regions] for region1 in regions])\n",
    "\n",
    "# Normalize the similarity matrix for the heatmap\n",
    "normalized_matrix = (matrix - np.min(matrix)) / (np.max(matrix) - np.min(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "042b3ca7-510a-4ae6-a9c0-5444aa0a6bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"720px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_37.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mask only the lower triangle by setting it to NaN, without affecting values in the upper triangle\n",
    "masked_matrix = np.triu(matrix, k=0)\n",
    "masked_matrix[masked_matrix == 0] = np.nan  # Mask zero values in lower triangle for better clarity\n",
    "\n",
    "# Generate heatmap with Plotly, including text annotations for each cell\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=masked_matrix,\n",
    "    x=regions,\n",
    "    y=regions,\n",
    "    colorscale=\"RdYlGn\",\n",
    "    colorbar=dict(title=\" \", titlefont=dict(size=20), tickfont=dict(size=20)),\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    "    text=[[f\"{val:.2f}\" if not np.isnan(val) else \"\" for val in row] for row in masked_matrix],  # Display values to 2 decimal points\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=20),  # Increase font size for the values\n",
    "    showscale=True\n",
    "))\n",
    "\n",
    "# Update layout to hide inner ticks and set the title\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"Region\",\n",
    "        titlefont=dict(size=20),  # Increase font size of the axis title\n",
    "        tickfont=dict(size=20),  # Increase font size of the tick labels\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(regions))),\n",
    "        ticktext=regions,\n",
    "        showgrid=False,\n",
    "        ticks=\"\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Region\",\n",
    "        titlefont=dict(size=20),  # Increase font size of the axis title\n",
    "        tickfont=dict(size=20),  # Increase font size of the tick labels\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(regions))),\n",
    "        ticktext=regions,\n",
    "        showgrid=False,\n",
    "        ticks=\"\"\n",
    "    ),\n",
    "    width=700,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Render the figure\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740bb01-1bfe-49aa-b7cc-9d1ca030c531",
   "metadata": {},
   "source": [
    "# Vit-patch16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32abd1-b90e-4491-b499-d42ee1e88205",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"South\": load_embeddings(\"vit\", \"south\"),\n",
    "    \"West\": load_embeddings(\"vit\", \"west\"),\n",
    "    \"Northeast\": load_embeddings(\"vit\", \"northeast\"),\n",
    "    \"Midwest\": load_embeddings(\"vit\", \"midwest\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04128b-be32-4c1a-b18f-89af63d06699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store similarities\n",
    "similarity_matrix = {}\n",
    "regions = list(datasets.keys())\n",
    "\n",
    "for i, region1 in enumerate(regions):\n",
    "    if region1 not in similarity_matrix:\n",
    "        similarity_matrix[region1] = {}  # Initialize the inner dictionary\n",
    "    for j, region2 in enumerate(regions):\n",
    "        if region2 not in similarity_matrix:\n",
    "            similarity_matrix[region2] = {}  # Ensure initialization for the symmetric entry\n",
    "        if i == j:\n",
    "            similarity_matrix[region1][region2] = 1.0  # Similarity with itself\n",
    "        elif j > i:  # Avoid redundant calculations\n",
    "            similarity = calculate_average_similarity(datasets[region1], datasets[region2])\n",
    "            similarity_matrix[region1][region2] = similarity\n",
    "            similarity_matrix[region2][region1] = similarity  # Symmetric matrix\n",
    "\n",
    "# Convert dictionary to a 2D numpy array for heatmap\n",
    "matrix = np.array([[similarity_matrix[region1][region2] for region2 in regions] for region1 in regions])\n",
    "\n",
    "# Normalize the similarity matrix for the heatmap\n",
    "normalized_matrix = (matrix - np.min(matrix)) / (np.max(matrix) - np.min(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bfd36c2-ffac-4261-a970-8a322ed22130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"720px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_32.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mask only the lower triangle by setting it to NaN, without affecting values in the upper triangle\n",
    "masked_matrix = np.triu(matrix, k=0)\n",
    "masked_matrix[masked_matrix == 0] = np.nan  # Mask zero values in lower triangle for better clarity\n",
    "\n",
    "# Generate heatmap with Plotly, including text annotations for each cell\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=masked_matrix,\n",
    "    x=regions,\n",
    "    y=regions,\n",
    "    colorscale=\"PuBuGn\",\n",
    "    colorbar=dict(title=\" \", titlefont=dict(size=20), tickfont=dict(size=20)),\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    "    text=[[f\"{val:.2f}\" if not np.isnan(val) else \"\" for val in row] for row in masked_matrix],  # Display values to 2 decimal points\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont=dict(size=20),  # Increase font size for the values\n",
    "    showscale=True\n",
    "))\n",
    "\n",
    "# Update layout to hide inner ticks and set the title\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"Region\",\n",
    "        titlefont=dict(size=20),  # Increase font size of the axis title\n",
    "        tickfont=dict(size=20),  # Increase font size of the tick labels\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(regions))),\n",
    "        ticktext=regions,\n",
    "        showgrid=False,\n",
    "        ticks=\"\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Region\",\n",
    "        titlefont=dict(size=20),  # Increase font size of the axis title\n",
    "        tickfont=dict(size=20),  # Increase font size of the tick labels\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(regions))),\n",
    "        ticktext=regions,\n",
    "        showgrid=False,\n",
    "        ticks=\"\"\n",
    "    ),\n",
    "    width=700,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# Render the figure\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1f4ea-fa83-4ef5-8f74-670dbe1b8957",
   "metadata": {},
   "source": [
    "# Finding number of shared vendors per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82b2fd-110c-464a-a58a-4c96a4021fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714af89-a697-460e-8e05-38f89cebbb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "south_df = pd.read_csv(\"../data/processed/south.csv\")[['TEXT', 'IMAGES', 'VENDOR', 'FACES', 'CITY']].drop_duplicates()\n",
    "midwest_df = pd.read_csv(\"../data/processed/midwest.csv\")[['TEXT', 'IMAGES', 'VENDOR', 'FACES', 'CITY']].drop_duplicates()\n",
    "west_df = pd.read_csv(\"../data/processed/west.csv\")[['TEXT', 'IMAGES', 'VENDOR', 'FACES', 'CITY']].drop_duplicates()\n",
    "northeast_df = pd.read_csv(\"../data/processed/northeast.csv\")[['TEXT', 'IMAGES', 'VENDOR', 'FACES', 'CITY']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452aa2e-43c4-4ca5-a75e-fcc66d473bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "south_vendors = list(south_df.VENDOR.unique())\n",
    "midwest_vendors = list(midwest_df.VENDOR.unique())\n",
    "west_vendors = list(west_df.VENDOR.unique())\n",
    "northeast_vendors = list(northeast_df.VENDOR.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3b7cfad-e171-4cc5-aa23-4edade0c229d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"620px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_28.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# List of all vendor lists and their labels\n",
    "vendor_lists = [south_vendors, midwest_vendors, west_vendors, northeast_vendors]\n",
    "regions = [\"South\", \"Midwest\", \"West\", \"Northeast\"]\n",
    "\n",
    "# Initialize an empty matrix for normalized pairwise common elements count\n",
    "normalized_common_elements_matrix = np.full((len(vendor_lists), len(vendor_lists)), np.nan)\n",
    "\n",
    "# Calculate normalized intersections and populate the upper triangle of the matrix\n",
    "for i in range(len(vendor_lists)):\n",
    "    for j in range(i, len(vendor_lists)):\n",
    "        if i == j:\n",
    "            # Self-intersection: normalized to 1 since it's fully contained\n",
    "            normalized_common_elements_matrix[i][j] = 1.0\n",
    "        else:\n",
    "            # Pairwise intersection normalized by the size of the second list\n",
    "            common_elements = set(vendor_lists[i]).intersection(vendor_lists[j])\n",
    "            normalized_count = len(common_elements) / len(set(vendor_lists[j]))\n",
    "            normalized_common_elements_matrix[i][j] = normalized_count\n",
    "\n",
    "# Create a heatmap with Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=normalized_common_elements_matrix,\n",
    "    x=regions,\n",
    "    y=regions,\n",
    "    colorscale=\"earth\",\n",
    "    colorbar=dict(title=\" \", titlefont=dict(size=20), tickfont=dict(size=20)),\n",
    "    zmin=0,\n",
    "    zmax=1,  # Since the normalized values range from 0 to 1\n",
    "    text=[[f\"{val:.2f}\" if not np.isnan(val) else \"\" for val in row] for row in normalized_common_elements_matrix],\n",
    "    texttemplate=\"<b>%{text}</b>\",  # Bold the text\n",
    "    textfont=dict(size=20),  # Increase font size for the values\n",
    "    showscale=True\n",
    "))\n",
    "\n",
    "# Update layout for a clean look\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        title=\"Region\",\n",
    "        titlefont=dict(size=20),  # Increase font size of the axis title\n",
    "        tickfont=dict(size=20),  # Increase font size of the tick labels\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(regions))),\n",
    "        ticktext=regions,\n",
    "        showgrid=False,\n",
    "        ticks=\"\"\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=\"Region\",\n",
    "        titlefont=dict(size=20),  # Increase font size of the axis title\n",
    "        tickfont=dict(size=20),  # Increase font size of the tick labels\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(regions))),\n",
    "        ticktext=regions,\n",
    "        showgrid=False,\n",
    "        ticks=\"\"\n",
    "    ),\n",
    "    width=600,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4e7bab6-1248-4fbb-b80b-8b56887a202e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"320px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_17.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# List of vendor lists for comparison with south_vendors\n",
    "comparison_lists = [south_vendors, midwest_vendors, west_vendors, northeast_vendors]\n",
    "regions = [\"South\", \"Midwest\", \"West\", \"Northeast\"]\n",
    "\n",
    "# Initialize an empty list for normalized comparisons with south_vendors\n",
    "normalized_values = []\n",
    "\n",
    "# Calculate normalized intersections only for south_vendors with each other list\n",
    "for i, comparison_list in enumerate(comparison_lists):\n",
    "    if i == 0:  # Self-intersection for South\n",
    "        normalized_values.append(1.0)  # Fully contained, so set to 1\n",
    "    else:\n",
    "        common_elements = set(south_vendors).intersection(comparison_list)\n",
    "        normalized_count = len(common_elements) / len(set(comparison_list))\n",
    "        normalized_values.append(normalized_count)\n",
    "\n",
    "# Convert normalized_values to a 2D array for the heatmap (to display vertically)\n",
    "normalized_values_matrix = np.array([normalized_values]).T\n",
    "\n",
    "# Create a single-column heatmap with Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=normalized_values_matrix,\n",
    "    x=[\"South\"],  # Single column for South comparisons\n",
    "    y=regions,\n",
    "    colorscale=\"earth\",\n",
    "    colorbar=dict(title=\"Common Vendors\"),\n",
    "    zmin=0,\n",
    "    zmax=1,  # Since normalized values range from 0 to 1\n",
    "    showscale=True\n",
    "))\n",
    "\n",
    "# Add annotations for each cell to display normalized values\n",
    "annotations = []\n",
    "for i, region in enumerate(regions):\n",
    "    value = normalized_values[i]\n",
    "    annotations.append(dict(\n",
    "        x=\"South\", \n",
    "        y=region,\n",
    "        text=f\"{value:.2f}\",  # Display value with two decimal places\n",
    "        showarrow=False,\n",
    "        font=dict(color=\"black\" if value > 0.5 else \"black\")  # Adjust text color for readability\n",
    "    ))\n",
    "\n",
    "# Update layout with annotations\n",
    "fig.update_layout(\n",
    "    # title=\"Normalized Common Elements with South Vendors\",\n",
    "    annotations=annotations,\n",
    "    xaxis=dict(title=\"\", tickmode=\"array\", tickvals=[0], ticktext=[\"South\"], showgrid=False, ticks=\"\"),\n",
    "    yaxis=dict(title=\"Region\", tickmode=\"array\", tickvals=list(range(len(regions))), ticktext=regions, showgrid=False),\n",
    "    width=300,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d26ca09-4f9a-48a6-95ec-d972a0b6f0b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trying to get performance of common and unique vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32c5623-1e00-4c35-816a-c5b967beeca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embedddings_for_e2e(model_name, city, mode=\"text\"):\n",
    "    assert mode in [\"text\", \"image\", \"multimodal\"]\n",
    "    \n",
    "    # Define directory mapping for models\n",
    "    model_dirs = {\n",
    "        \"declutr-vit\": \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/trained_declutr_vit/CE+SupCon\",\n",
    "        \"CE-SupCon-mean-0.5\": \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/multimodal_baselines/E2E/CE-SupCon-mean-0.5\",\n",
    "        \"declutr-vit-face\": \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/error_analysis/multimodal_baseline/trained_declutr-vit/face\",\n",
    "        \"declutr-vit-noface\": \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/error_analysis/multimodal_baseline/trained_declutr-vit/noface\",\n",
    "    }\n",
    "    \n",
    "    # Check if model_name is valid\n",
    "    if model_name not in model_dirs:\n",
    "        raise ValueError(f\"Model '{model_name}' not implemented\")\n",
    "        \n",
    "    emb_dir = model_dirs[model_name]\n",
    "    \n",
    "    if model_name == \"declutr-vit\":\n",
    "        filenames = {\n",
    "            \"train_emb\": f\"{city}_{mode}data_train.pt\",\n",
    "            \"train_labels\": f\"{city}_labels_{mode}_train.pt\",\n",
    "            \"test_emb\": f\"{city}_{mode}data_test.pt\",\n",
    "            \"test_labels\": f\"{city}_labels_{mode}_test.pt\",\n",
    "        }\n",
    "    else:\n",
    "        filenames = {\n",
    "            \"train_emb\": f\"{city}_{mode}data_train.pt\",\n",
    "            \"train_labels\": f\"{city}_labels_train.pt\",\n",
    "            \"test_emb\": f\"{city}_{mode}data_test.pt\",\n",
    "            \"test_labels\": f\"{city}_labels_test.pt\",\n",
    "        }\n",
    "    \n",
    "    # Load embeddings and labels\n",
    "    train_emb = torch.load(os.path.join(emb_dir, filenames[\"train_emb\"]), map_location=torch.device('cpu'))\n",
    "    train_labels = torch.load(os.path.join(emb_dir, filenames[\"train_labels\"]), map_location=torch.device('cpu'))\n",
    "    test_emb = torch.load(os.path.join(emb_dir, filenames[\"test_emb\"]), map_location=torch.device('cpu'))\n",
    "    test_labels = torch.load(os.path.join(emb_dir, filenames[\"test_labels\"]), map_location=torch.device('cpu'))\n",
    "    \n",
    "    embeddings = torch.cat((train_emb, test_emb), dim=0)\n",
    "    labels = torch.cat((train_labels, test_labels), dim=0)\n",
    "    \n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf613cf-6a2a-4f88-a079-7804eefcba9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, labels1 = load_embedddings_for_e2e(\"CE-SupCon-mean-0.5\", \"south\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472b0633-4990-496a-bb99-974cc4f869aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, labels2 = load_embedddings_for_e2e(\"CE-SupCon-mean-0.5\", \"west\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdedc86e-f5f2-44d1-b173-ea29ecd845fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 725,  170, 1454,  ...,  923,  923,  923])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc75130-31b8-4fe4-95c1-2ec7c8643c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common elements: tensor([   0,    1,    2,    3,    7,    8,   14,   15,   16,   17,   19,   20,\n",
      "          21,   23,   24,   26,   28,   29,   31,   34,   35,   38,   41,   43,\n",
      "          44,   45,   46,   47,   48,   49,   55,   57,   60,   61,   62,   65,\n",
      "          66,   68,   69,   71,   73,   77,   78,   80,   81,   84,   85,   86,\n",
      "          87,   88,   89,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
      "         100,  102,  104,  107,  108,  109,  110,  111,  114,  115,  122,  123,\n",
      "         125,  126,  127,  128,  129,  130,  549,  551,  553,  561,  570,  576,\n",
      "         585,  589,  594,  595,  596,  598,  604,  613,  620,  621,  624,  628,\n",
      "         639,  640,  643,  644,  652,  654,  655,  658,  659,  660,  663,  669,\n",
      "         671,  678,  683,  701,  702,  706,  712,  716,  722,  736,  739,  752,\n",
      "         758,  763,  773,  775,  779,  782,  786,  788,  791,  793,  796,  797,\n",
      "         802,  804,  806,  807,  808,  824,  826,  842,  844,  846,  849,  851,\n",
      "         852,  857,  862,  865,  873,  874,  876,  877,  878,  894,  898,  899,\n",
      "         901,  904,  910,  912,  915,  917,  920,  927,  928,  929,  931,  939,\n",
      "         942,  945,  951,  956,  957,  960,  968,  972,  973,  976,  978,  982,\n",
      "         985,  988,  994, 1005, 1006, 1010, 1016, 1018, 1024, 1031, 1032, 1037,\n",
      "        1039, 1043, 1044, 1051, 1054, 1056, 1060, 1064, 1065, 1068, 1078, 1079,\n",
      "        1081, 1084, 1086, 1088, 1094, 1096, 1100, 1103, 1112, 1116, 1126, 1131,\n",
      "        1139, 1159, 1164, 1166, 1172, 1180, 1181, 1188, 1202, 1238, 1247, 1261,\n",
      "        1262, 1288, 1304, 1305, 1310, 1335, 1340, 1362, 1369, 1371, 1377, 1378,\n",
      "        1379, 1380, 1382, 1383, 1384, 1388, 1389, 1391, 1393, 1405, 1408, 1409,\n",
      "        1411, 1412, 1417, 1418, 1422, 1424, 1425, 1428, 1429, 1431, 1433, 1435,\n",
      "        1436, 1439, 1442, 1443, 1450, 1463, 1466, 1467, 1468, 1470, 1471, 1473,\n",
      "        1477, 1479, 1481, 1491, 1498, 1511, 1519, 1521, 1522, 1539, 1541, 1542,\n",
      "        1550, 1553, 1556, 1561, 1582, 1584, 1588, 1592, 1597, 1598, 1600, 1614,\n",
      "        1615, 1629, 1634, 1639, 1641, 1643, 1648, 1651, 1652, 1653, 1675, 1676])\n",
      "Unique to tensor1: tensor([2048, 2049, 2051,  ..., 2036, 2041, 2047])\n",
      "Unique to tensor2: tensor([ 513,  514,  516,  517, 1540,  520,  523,  524,  525,  526,  527, 1552,\n",
      "         529,  530,  531,  534, 1562,  539,  542,  543,   32, 1057, 1568,  550,\n",
      "         555,  560, 1073, 1074,  563,  569,   58,  571,  573, 1602, 1603,  583,\n",
      "        1099, 1619, 1623, 1118, 1121, 1127, 1657, 1658, 1659, 1171,  662,  665,\n",
      "         672,  676, 1216,  710,  718, 1239, 1250, 1251, 1300, 1303, 1307, 1317,\n",
      "        1324, 1328,  819,  308,  309,  310, 1334,  312, 1336,  314,  317,  321,\n",
      "         322,  325,  331,  332, 1357,  337,  338,  339,  340,  341,  850,  343,\n",
      "         344, 1361,  346,  347,  860,  350,  351,  353,  357,  358, 1381,  361,\n",
      "        1385, 1386,  365, 1390,  368, 1392,  882,  371, 1395, 1396, 1398,  375,\n",
      "        1400,  377,  379, 1404,  382,  383,  389,  390,  391,  392,  393,  906,\n",
      "         395,  396,  397, 1413, 1415,  400,  401, 1423, 1427,  404,  407,  408,\n",
      "         409, 1437,  416,  417,  418,  420,  421, 1444,  423,  425, 1449,  427,\n",
      "         428,  429,  431,  432,  433,  434, 1456,  436,  437,  950,  439,  440,\n",
      "         441,  443,  444,  445,  446,  451,  452,  966,  458,  459,  460,  461,\n",
      "         971,  463,  975, 1484,  979,  981,  470, 1416, 1497,  479,  480,  482,\n",
      "         483, 1507,  997,  998,  492, 1516,  494,  495,  498,  499, 1524,  502,\n",
      "        1526,  506,  508,  509,  510, 1535])\n"
     ]
    }
   ],
   "source": [
    "# Convert tensors to sets for set operations\n",
    "set1 = set(labels1.tolist())\n",
    "set2 = set(labels2.tolist())\n",
    "\n",
    "# Common elements\n",
    "common_elements = set1.intersection(set2)\n",
    "\n",
    "# Unique elements\n",
    "unique_to_tensor1 = set1 - set2\n",
    "unique_to_tensor2 = set2 - set1\n",
    "\n",
    "# Convert back to tensors if needed\n",
    "common_tensor = torch.tensor(list(common_elements))\n",
    "unique_tensor1 = torch.tensor(list(unique_to_tensor1))\n",
    "unique_tensor2 = torch.tensor(list(unique_to_tensor2))\n",
    "\n",
    "# Output results\n",
    "print(\"Common elements:\", common_tensor)\n",
    "print(\"Unique to tensor1:\", unique_tensor1)\n",
    "print(\"Unique to tensor2:\", unique_tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e702e-413c-4559-8d4f-df6ac4f4ee63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0b9ac-e950-4a21-862b-da8f05c28a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HT",
   "language": "python",
   "name": "ht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
