{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e5967c78-0ee2-4ef3-b875-5cb347c6d86a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Code Overview\n",
    "# Performs similarity search for all the pre-trained unimodal (text-only and vision-only) baselines without any fine-tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d24ebd0",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09621eb2-64ed-4658-bfe8-954ad88fb665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle\n",
    "# import numpy as np\n",
    "import numpy\n",
    "from itertools import product\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65be179-db80-4a7a-8b41-9f8e51f0a297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = faiss.StandardGpuResources()  # use a single GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53bb8d-1443-4f2b-8e38-6ab5b6b82049",
   "metadata": {},
   "source": [
    "# Loading the trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c8435c-54ae-4700-a470-aae6cb47eed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_embeddings(model_name, city):\n",
    "    if model_name == \"declutr\":\n",
    "        emb_dir = os.path.join(os.getcwd(), \"/workspace/persistent/HTClipper/models/pickled/embeddings/grouped-and-masked/pretrained_declutr\")\n",
    "    else:\n",
    "        emb_dir = os.path.join(os.getcwd(), \"../models/pickled/embeddings/pretrained_styleEmbedding\")\n",
    "        \n",
    "    train_label_filename = \"pretrained_checkpoint_\" + model_name + \"_\" + city + \"_labels_train.pt\"\n",
    "    train_data_filename = \"pretrained_checkpoint_\" + model_name  + \"_\" + city + \"_data_train.pt\"\n",
    "    test_label_filename = \"pretrained_checkpoint_\" + model_name + \"_\" + city + \"_labels_test.pt\"\n",
    "    test_data_filename = \"pretrained_checkpoint_\" + model_name  + \"_\" + city + \"_data_test.pt\"\n",
    "    \n",
    "    train_emb = torch.load(os.path.join(emb_dir, train_data_filename), map_location=torch.device('cpu'))\n",
    "    train_labels = torch.load(os.path.join(emb_dir, train_label_filename), map_location=torch.device('cpu'))\n",
    "    \n",
    "    test_emb = torch.load(os.path.join(emb_dir, test_data_filename), map_location=torch.device('cpu'))\n",
    "    test_labels = torch.load(os.path.join(emb_dir, test_label_filename), map_location=torch.device('cpu'))\n",
    "    \n",
    "    return train_emb, train_labels, test_emb, test_labels    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa472af-ef70-4dca-8670-a3249a4de322",
   "metadata": {},
   "source": [
    "# R-Precision metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddcfa6e-9456-4e0b-a5c2-9d0154bcd301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    recall_list = []\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        act_set = set(act.numpy())  # Convert PyTorch tensor to NumPy array, then to set\n",
    "        pred_set = set(pred[:k].numpy())  # Convert PyTorch tensor to NumPy array, then to set\n",
    "        recall_list.append(round(len(act_set & pred_set) / float(len(act_set)), 2))\n",
    "    return recall_list\n",
    "\n",
    "def generate_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)\n",
    "\n",
    "    unique_vendors = torch.unique(test_labels)\n",
    "    train_labels_np = train_labels.numpy()\n",
    "\n",
    "    vendor_dict = {int(vendor_id): (train_labels == vendor_id).sum().item() for vendor_id in unique_vendors}\n",
    "    \n",
    "    r_precision_score = {}\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=\"Calculating R-precision\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        # Skip if there are no test embeddings for this vendor_id\n",
    "        if len(test_adsidx) == 0:\n",
    "            continue\n",
    "\n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "        \n",
    "        # Ensure test_vendor_embeddings is a 2D array\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = test_vendor_embeddings[np.newaxis, :]\n",
    "\n",
    "        k = vendor_dict[vendor_id]\n",
    "        if k == 0:  # Skip if k is 0, meaning there are no relevant embeddings to search for\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            _, I = gpu_index_flat.search(test_vendor_embeddings, k)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error searching for vendor_id {vendor_id} with shape {test_vendor_embeddings.shape}: {e}\")\n",
    "            continue\n",
    "\n",
    "        predicted_label_list = [torch.tensor(I[index]) for index in range(len(test_adsidx))]\n",
    "        true_label_list = [torch.where(train_labels == vendor_id)[0] for _ in range(len(test_adsidx))]\n",
    "        \n",
    "        r_precision_score[vendor_id] = np.mean(recall_at_k(true_label_list, predicted_label_list, k))\n",
    "    \n",
    "    r_precision_mean = np.mean(list(r_precision_score.values()))\n",
    "    r_precision_std = np.std(list(r_precision_score.values()))\n",
    "\n",
    "    print(f\"R precision mean: {round(r_precision_mean, 4)} ± {round(r_precision_std, 2)}\")\n",
    "    \n",
    "    return r_precision_mean, r_precision_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30700dd6-ad20-4678-857e-dd05134d0fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_mrr_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)  # Inner Product (cosine similarity)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)  # Directly use numpy array\n",
    "\n",
    "    mrr_scores = []\n",
    "\n",
    "    unique_vendors = torch.unique(test_labels)\n",
    "    train_labels_np = train_labels.numpy()\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=f\"Calculating MRR@{k}\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "        if len(test_adsidx) == 0:\n",
    "            continue\n",
    "        \n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "        \n",
    "        # Ensure test_vendor_embeddings is a 2D array\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = test_vendor_embeddings[np.newaxis, :]\n",
    "\n",
    "        try:\n",
    "            D, I = gpu_index_flat.search(test_vendor_embeddings, k)  # Retrieve the top k results\n",
    "        except ValueError as e:\n",
    "            print(f\"Error searching for vendor_id {vendor_id} with shape {test_vendor_embeddings.shape}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # I is the indices of the nearest neighbors\n",
    "        for idx, indices in enumerate(I):\n",
    "            correct_indices = np.where(train_labels_np == vendor_id)[0]\n",
    "            for rank, index in enumerate(indices, start=1):\n",
    "                if index in correct_indices:\n",
    "                    mrr_scores.append(1.0 / rank)\n",
    "                    break\n",
    "            else:\n",
    "                mrr_scores.append(0.0)\n",
    "\n",
    "    mrr_mean = np.mean(mrr_scores) if mrr_scores else 0\n",
    "    mrr_std = np.std(mrr_scores) if mrr_scores else 0\n",
    "    print(f\"MRR@{k} mean: {round(mrr_mean, 4)} ± {round(mrr_std, 2)}\")\n",
    "\n",
    "    return mrr_mean, mrr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfaddd11-7212-4886-9b1b-47d4203e5efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)  # Inner Product (cosine similarity)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)  # Directly use numpy array\n",
    "\n",
    "    unique_vendors = torch.unique(test_labels)\n",
    "    train_labels_np = train_labels.numpy()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=f\"Calculating Macro-F1@{k}\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "        if len(test_adsidx) == 0:\n",
    "            continue\n",
    "        \n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "        \n",
    "        # Ensure test_vendor_embeddings is a 2D array\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = test_vendor_embeddings[np.newaxis, :]\n",
    "\n",
    "        try:\n",
    "            D, I = gpu_index_flat.search(test_vendor_embeddings, k)  # Retrieve the top k results\n",
    "        except ValueError as e:\n",
    "            print(f\"Error searching for vendor_id {vendor_id} with shape {test_vendor_embeddings.shape}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Collect true labels and predicted labels for micro-F1 calculation\n",
    "        for indices in I:\n",
    "            true_labels = [vendor_id] * k  # True labels are the same vendor_id for the current test sample\n",
    "            predicted_labels = train_labels_np[indices]  # Predicted labels are the labels of the top k retrieved samples\n",
    "\n",
    "            y_true.extend(true_labels)\n",
    "            y_pred.extend(predicted_labels)\n",
    "\n",
    "    # Calculate micro-F1 score\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Macro-F1@{k}: {macro_f1}\")\n",
    "    \n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eead7f08-3afd-4fd2-a8b8-cca254afca21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_macro_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    \n",
    "    # train_embeddings are already NumPy arrays\n",
    "    gpu_index_flat.add(train_embeddings)\n",
    "    unique_vendors = torch.unique(test_labels)\n",
    "    train_labels_np = train_labels.numpy()\n",
    "\n",
    "    vendor_dict = {int(vendor_id): np.sum(train_labels_np == int(vendor_id)) for vendor_id in unique_vendors}\n",
    "\n",
    "    r_precision_score = {}\n",
    "    total_samples = 0  # Total number of samples for all classes\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=\"Calculating R-precision\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if len(test_adsidx) == 0 or vendor_dict[vendor_id] == 0:\n",
    "            continue\n",
    "\n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx.numpy()]\n",
    "        \n",
    "        # Ensure test_vendor_embeddings is a 2D array\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = np.expand_dims(test_vendor_embeddings, axis=0)\n",
    "\n",
    "        k = vendor_dict[vendor_id]\n",
    "        \n",
    "        # Check if k is within the valid range\n",
    "        if k > train_embeddings.shape[0]:\n",
    "            print(f\"Warning: k ({k}) is greater than the number of training samples ({train_embeddings.shape[0]}), adjusting k to maximum possible.\")\n",
    "            k = train_embeddings.shape[0]\n",
    "\n",
    "        try:\n",
    "            _, I = gpu_index_flat.search(test_vendor_embeddings, int(k))\n",
    "        except Exception as e:\n",
    "            print(f\"Error during FAISS search for vendor_id {vendor_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        predicted_label_list = [torch.tensor(I[index]) for index in range(len(test_adsidx))]\n",
    "        true_label_list = [torch.where(train_labels == vendor_id)[0] for _ in range(len(test_adsidx))]\n",
    "        \n",
    "        r_precision_score[vendor_id] = np.mean(recall_at_k(true_label_list, predicted_label_list, k))\n",
    "        total_samples += len(test_adsidx)  # Add the number of samples for this class\n",
    "\n",
    "    # Calculate the weighted mean of R-Precision\n",
    "    weighted_r_precision_sum = sum(r_precision_score[vendor_id] * len((test_labels == vendor_id).nonzero(as_tuple=True)[0]) for vendor_id in r_precision_score.keys())\n",
    "    macro_r_precision = weighted_r_precision_sum / total_samples\n",
    "\n",
    "    print(f\"Macro R-precision: {macro_r_precision}\")\n",
    "    \n",
    "    return macro_r_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "528a0ef7-ccda-434b-8a2c-d7c707707458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def precision_at_k(actual, predicted, k):\n",
    "    precision_list = []\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        act_set = set(act.numpy())\n",
    "        pred_set = set(pred[:k].numpy())\n",
    "        precision_list.append(len(act_set & pred_set) / float(k))\n",
    "    return precision_list\n",
    "\n",
    "def f1_at_k(actual, predicted, k):\n",
    "    f1_list = []\n",
    "    precision_list = precision_at_k(actual, predicted, k)\n",
    "    recall_list = recall_at_k(actual, predicted, k)\n",
    "    for precision, recall in zip(precision_list, recall_list):\n",
    "        if precision + recall > 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "        f1_list.append(f1)\n",
    "    return f1_list\n",
    "\n",
    "def generate_macro_f1_at_x_results(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)\n",
    "\n",
    "    unique_vendors = torch.unique(test_labels)\n",
    "    train_labels_np = train_labels.numpy()\n",
    "\n",
    "    vendor_dict = {int(vendor_id): np.sum(train_labels_np == int(vendor_id)) for vendor_id in unique_vendors}\n",
    "    f1_score_list = []\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=\"Calculating Macro-F1@X\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if len(test_adsidx) == 0 or vendor_dict[vendor_id] == 0:\n",
    "            continue\n",
    "\n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "        if isinstance(test_vendor_embeddings, torch.Tensor):\n",
    "            test_vendor_embeddings = test_vendor_embeddings.numpy()\n",
    "\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = np.expand_dims(test_vendor_embeddings, axis=0)\n",
    "\n",
    "        k = vendor_dict[vendor_id]\n",
    "        if k > train_embeddings.shape[0]:\n",
    "            k = train_embeddings.shape[0]\n",
    "\n",
    "        _, I = gpu_index_flat.search(test_vendor_embeddings, int(k))\n",
    "\n",
    "        predicted_label_list = [torch.tensor(I[index]) for index in range(len(test_adsidx))]\n",
    "        true_label_list = [torch.where(train_labels == vendor_id)[0] for _ in range(len(test_adsidx))]\n",
    "        \n",
    "        f1_score_list.extend(f1_at_k(true_label_list, predicted_label_list, k))\n",
    "\n",
    "    macro_f1_mean = np.mean(f1_score_list)\n",
    "    macro_f1_std = np.std(f1_score_list)\n",
    "\n",
    "    print(f\"Macro F1@X: {round(macro_f1_mean, 4)} ± {round(macro_f1_std, 2)}\")\n",
    "    \n",
    "    return macro_f1_mean, macro_f1_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ac042-9c21-401e-8958-d81145b12148",
   "metadata": {},
   "source": [
    "# Declutr model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d94961be-49b4-4752-ba97-593328054312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import hashlib\n",
    "\n",
    "def remove_duplicate_embeddings(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    \"\"\"\n",
    "    Removes duplicate embeddings between train and test sets using hashing.\n",
    "\n",
    "    Args:\n",
    "        train_embeddings (torch.Tensor): Embeddings from the training set.\n",
    "        train_labels (torch.Tensor): Labels corresponding to the training embeddings.\n",
    "        test_embeddings (torch.Tensor): Embeddings from the test set.\n",
    "        test_labels (torch.Tensor): Labels corresponding to the test embeddings.\n",
    "\n",
    "    Returns:\n",
    "        unique_train_embeddings (torch.Tensor): Unique embeddings from the training set.\n",
    "        unique_train_labels (torch.Tensor): Labels corresponding to the unique training embeddings.\n",
    "        unique_test_embeddings (torch.Tensor): Unique embeddings from the test set (excluding duplicates with train set).\n",
    "        unique_test_labels (torch.Tensor): Labels corresponding to the unique test embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def hash_embedding(embedding):\n",
    "        # Ensure the embedding is contiguous in memory and of type float32\n",
    "        embedding = embedding.contiguous().view(-1).float()\n",
    "        # Round to reduce the impact of floating-point precision errors\n",
    "        embedding = torch.round(embedding * 1e6) / 1e6  # Adjust precision as needed\n",
    "        # Convert the embedding to bytes\n",
    "        emb_bytes = embedding.numpy().tobytes()\n",
    "        # Compute MD5 hash\n",
    "        return hashlib.md5(emb_bytes).hexdigest()\n",
    "\n",
    "    # Create dictionaries mapping hashes to embeddings and labels for the train set\n",
    "    train_hash_embedding_label_dict = {}\n",
    "    for emb, label in zip(train_embeddings, train_labels):\n",
    "        emb_hash = hash_embedding(emb)\n",
    "        # Store the embedding and label only if the hash is not already in the dictionary\n",
    "        if emb_hash not in train_hash_embedding_label_dict:\n",
    "            train_hash_embedding_label_dict[emb_hash] = (emb, label.item())\n",
    "\n",
    "    # Create dictionaries mapping hashes to embeddings and labels for the test set\n",
    "    test_hash_embedding_label_dict = {}\n",
    "    for emb, label in zip(test_embeddings, test_labels):\n",
    "        emb_hash = hash_embedding(emb)\n",
    "        # Store the embedding and label only if the hash is not already in the dictionary\n",
    "        if emb_hash not in test_hash_embedding_label_dict:\n",
    "            test_hash_embedding_label_dict[emb_hash] = (emb, label.item())\n",
    "\n",
    "    # Identify common hashes between train and test sets\n",
    "    common_hashes = set(train_hash_embedding_label_dict.keys()).intersection(set(test_hash_embedding_label_dict.keys()))\n",
    "\n",
    "    # Remove duplicates from the test set\n",
    "    unique_test_hashes = set(test_hash_embedding_label_dict.keys()) - common_hashes\n",
    "\n",
    "    # Reconstruct unique embeddings and labels for the train set\n",
    "    unique_train_embeddings_list = [emb_label[0] for emb_label in train_hash_embedding_label_dict.values()]\n",
    "    unique_train_labels_list = [emb_label[1] for emb_label in train_hash_embedding_label_dict.values()]\n",
    "\n",
    "    # Reconstruct unique embeddings and labels for the test set\n",
    "    unique_test_embeddings_list = [test_hash_embedding_label_dict[h][0] for h in unique_test_hashes]\n",
    "    unique_test_labels_list = [test_hash_embedding_label_dict[h][1] for h in unique_test_hashes]\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    unique_train_embeddings = torch.stack(unique_train_embeddings_list)\n",
    "    unique_train_labels = torch.tensor(unique_train_labels_list)\n",
    "\n",
    "    unique_test_embeddings = torch.stack(unique_test_embeddings_list)\n",
    "    unique_test_labels = torch.tensor(unique_test_labels_list)\n",
    "\n",
    "    return unique_train_embeddings, unique_train_labels, unique_test_embeddings, unique_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b508efd-7c55-4bb8-ad35-ac48c880b5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_members(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    \"\"\"\n",
    "    Filters test_embeddings and test_labels by removing entries whose labels do not exist in train_labels.\n",
    "\n",
    "    Parameters:\n",
    "    - train_embeddings (torch.Tensor): Embeddings for the training data.\n",
    "    - train_labels (torch.Tensor): Labels for the training data.\n",
    "    - test_embeddings (torch.Tensor): Embeddings for the test data.\n",
    "    - test_labels (torch.Tensor): Labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "    - train_embeddings (torch.Tensor): Original training embeddings (unchanged).\n",
    "    - train_labels (torch.Tensor): Original training labels (unchanged).\n",
    "    - filtered_test_embeddings (torch.Tensor): Filtered test embeddings.\n",
    "    - filtered_test_labels (torch.Tensor): Filtered test labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure labels are on the same device\n",
    "    if train_labels.device != test_labels.device:\n",
    "        train_labels = train_labels.to(test_labels.device)\n",
    "\n",
    "    # Use torch.isin to create a mask of test labels that exist in train labels\n",
    "    if hasattr(torch, 'isin'):\n",
    "        # torch.isin is available in PyTorch 1.10 and later\n",
    "        mask = torch.isin(test_labels, train_labels)\n",
    "    else:\n",
    "        # For older versions of PyTorch, convert to NumPy arrays\n",
    "        train_labels_np = train_labels.cpu().numpy()\n",
    "        test_labels_np = test_labels.cpu().numpy()\n",
    "        mask_np = np.isin(test_labels_np, train_labels_np)\n",
    "        mask = torch.from_numpy(mask_np).to(test_labels.device)\n",
    "\n",
    "    # Apply the mask to filter test embeddings and labels\n",
    "    filtered_test_embeddings = test_embeddings[mask]\n",
    "    filtered_test_labels = test_labels[mask]\n",
    "\n",
    "    return train_embeddings, train_labels, filtered_test_embeddings, filtered_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d0edf-166e-4661-8494-2cc6e4166a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43dcbe61-04dc-40d6-ad7c-97f31a31845f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "City: south\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 964/964 [00:00<00:00, 2571.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.2248 ± 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 964/964 [00:00<00:00, 4572.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.3265 ± 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 964/964 [00:00<00:00, 2529.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.2223 ± 0.3\n",
      "--------------------------------------------------\n",
      "City: midwest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 624/624 [00:00<00:00, 3194.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.2866 ± 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 624/624 [00:00<00:00, 5686.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.3943 ± 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 624/624 [00:00<00:00, 3129.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.2804 ± 0.36\n",
      "--------------------------------------------------\n",
      "City: west\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 259/259 [00:00<00:00, 3848.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.3479 ± 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 259/259 [00:00<00:00, 6851.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.3139 ± 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 259/259 [00:00<00:00, 3633.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.2731 ± 0.36\n",
      "--------------------------------------------------\n",
      "City: northeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 293/293 [00:00<00:00, 4470.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.3385 ± 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 293/293 [00:00<00:00, 7374.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.4037 ± 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 293/293 [00:00<00:00, 4735.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.3801 ± 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r_precision_dict, mrr_dict = ({} for i in range(2))\n",
    "for city_ in [\"south\", \"midwest\", \"west\", \"northeast\"]:    \n",
    "    print(\"-\"*50)\n",
    "    print(\"City:\", city_)\n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = load_embeddings(model_name=\"declutr\", city=city_)\n",
    "    \n",
    "    train_embeddings = torch.tensor(train_embeddings)\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    test_embeddings = torch.tensor(test_embeddings)\n",
    "    test_labels = torch.tensor(test_labels)\n",
    "    \n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = remove_duplicate_embeddings(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = find_members(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    \n",
    "    train_embeddings = train_embeddings.detach().cpu().numpy()\n",
    "    # train_labels = train_labels.detach().cpu().numpy()\n",
    "    test_embeddings = test_embeddings.detach().cpu().numpy()\n",
    "    # test_labels = test_labels.detach().cpu().numpy()\n",
    "    \n",
    "    r_precision_mean, r_precision_std = generate_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    mrr_mean, mrr_std = calculate_mrr_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=1)\n",
    "    # macro_f1_1 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=1)\n",
    "    # macro_f1_10 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10)\n",
    "    # macro_f1_100 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=100)\n",
    "    # macro_average_r_precision = generate_macro_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    _, _  = generate_macro_f1_at_x_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "     \n",
    "    # r_precision_dict[city_] = (r_precision_mean, r_precision_std)\n",
    "    # mrr_dict[city_] = (mrr_mean, mrr_std)\n",
    "    \n",
    "#with open('../models/pickled/embeddings/pretrained_declutr/rprecision.pickle', 'wb') as handle:\n",
    "#    pickle.dump(r_precision_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open('../models/pickled/embeddings/pretrained_declutr/mrr.pickle', 'wb') as handle:\n",
    "#    pickle.dump(mrr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c7c8fb7-1724-40e5-9170-b2aed6d9faa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "City: south\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 964/964 [00:00<00:00, 1629.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.5318 ± 0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 964/964 [00:00<00:00, 2699.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.7532 ± 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 964/964 [00:00<00:00, 1612.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.4887 ± 0.37\n",
      "--------------------------------------------------\n",
      "City: midwest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 624/624 [00:00<00:00, 2260.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.6207 ± 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 624/624 [00:00<00:00, 3930.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.6954 ± 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 624/624 [00:00<00:00, 2244.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.5397 ± 0.42\n",
      "--------------------------------------------------\n",
      "City: west\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 259/259 [00:00<00:00, 3126.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.749 ± 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 259/259 [00:00<00:00, 5373.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.6104 ± 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 259/259 [00:00<00:00, 2979.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.568 ± 0.43\n",
      "--------------------------------------------------\n",
      "City: northeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 293/293 [00:00<00:00, 3704.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.6499 ± 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 293/293 [00:00<00:00, 5853.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 mean: 0.7807 ± 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Macro-F1@X: 100%|██████████| 293/293 [00:00<00:00, 3774.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1@X: 0.6694 ± 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "r_precision_dict, mrr_dict = ({} for i in range(2))\n",
    "for city_ in [\"south\", \"midwest\", \"west\", \"northeast\"]:    \n",
    "    print(\"-\"*50)\n",
    "    print(\"City:\", city_)\n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = load_embeddings(model_name=\"declutr\", city=city_)\n",
    "    \n",
    "    train_embeddings = torch.tensor(train_embeddings)\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    test_embeddings = torch.tensor(test_embeddings)\n",
    "    test_labels = torch.tensor(test_labels)\n",
    "    \n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = remove_duplicate_embeddings(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = find_members(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    \n",
    "    train_embeddings = train_embeddings.detach().cpu().numpy()\n",
    "    # train_labels = train_labels.detach().cpu().numpy()\n",
    "    test_embeddings = test_embeddings.detach().cpu().numpy()\n",
    "    # test_labels = test_labels.detach().cpu().numpy()\n",
    "    \n",
    "    # Normalize training embeddings\n",
    "    faiss.normalize_L2(train_embeddings)\n",
    "    # Normalize test embeddings\n",
    "    faiss.normalize_L2(test_embeddings)\n",
    "\n",
    "    r_precision_mean, r_precision_std = generate_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    mrr_mean, mrr_std = calculate_mrr_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=1)\n",
    "    # macro_f1_1 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=1)\n",
    "    # macro_f1_10 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10)\n",
    "    # macro_f1_100 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=100)\n",
    "    # macro_average_r_precision = generate_macro_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    _, _  = generate_macro_f1_at_x_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "     \n",
    "    # r_precision_dict[city_] = (r_precision_mean, r_precision_std)\n",
    "    # mrr_dict[city_] = (mrr_mean, mrr_std)\n",
    "    \n",
    "#with open('../models/pickled/embeddings/pretrained_declutr/rprecision.pickle', 'wb') as handle:\n",
    "#    pickle.dump(r_precision_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open('../models/pickled/embeddings/pretrained_declutr/mrr.pickle', 'wb') as handle:\n",
    "#    pickle.dump(mrr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1955c0b-e76a-49f6-af56-6c35ebb90cb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Style Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e38aadf-5269-4698-b27f-ccb5a94e8c07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: chicago\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 490/490 [00:00<00:00, 3255.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.04380285181322671\n",
      "R precision std: 0.14621349882076917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 490/490 [00:00<00:00, 6089.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.07626514611546685\n",
      "MRR@1 Std: 0.26542187853199545\n",
      "City: atlanta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 471/471 [00:00<00:00, 3946.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.04968652458652459\n",
      "R precision std: 0.1567127507156519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 471/471 [00:00<00:00, 6467.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.07265388496468214\n",
      "MRR@1 Std: 0.25956752101181857\n",
      "City: detroit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 153/153 [00:00<00:00, 4600.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.10399391534391535\n",
      "R precision std: 0.20905570292954856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 153/153 [00:00<00:00, 7412.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.1157556270096463\n",
      "MRR@1 Std: 0.31993165180277167\n",
      "City: houston\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 422/422 [00:00<00:00, 3842.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.06559834893975931\n",
      "R precision std: 0.1840278621241181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 422/422 [00:00<00:00, 6554.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.07065750736015702\n",
      "MRR@1 Std: 0.2562518761176323\n",
      "City: dallas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 377/377 [00:00<00:00, 4237.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.06683864083108589\n",
      "R precision std: 0.18458040934132475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 377/377 [00:00<00:00, 6934.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.06427688504326329\n",
      "MRR@1 Std: 0.24524552410268038\n",
      "City: NY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 309/309 [00:00<00:00, 4933.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.0815415244596132\n",
      "R precision std: 0.2264429605299262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 309/309 [00:00<00:00, 7593.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.09038461538461538\n",
      "MRR@1 Std: 0.28673199452867226\n",
      "City: SF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 268/268 [00:00<00:00, 3969.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.09614669797428418\n",
      "R precision std: 0.22998653947544206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 268/268 [00:00<00:00, 6576.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.09494640122511486\n",
      "MRR@1 Std: 0.2931408912443202\n",
      "City: canada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating R-precision: 100%|██████████| 149/149 [00:00<00:00, 5323.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R precision mean: 0.1725718112244898\n",
      "R precision std: 0.3262201418683189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@1: 100%|██████████| 149/149 [00:00<00:00, 7852.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1 Mean: 0.20353982300884957\n",
      "MRR@1 Std: 0.40263055455140984\n"
     ]
    }
   ],
   "source": [
    "r_precision_dict, mrr_dict = ({} for i in range(2))\n",
    "\n",
    "for city_ in [\"chicago\", \"atlanta\", \"detroit\", \"houston\", \"dallas\", \"NY\", \"SF\", \"canada\"]:\n",
    "    print(\"City:\", city_)\n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = load_embeddings(model_name=\"styleEmbedding\", city=city_)\n",
    "    r_precision_mean, r_precision_std = generate_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    mrr_mean, mrr_std = calculate_mrr_at_1(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    r_precision_dict[city_] = (r_precision_mean, r_precision_std)\n",
    "    mrr_dict[city_] = (mrr_mean, mrr_std)\n",
    "    \n",
    "with open('../models/pickled/embeddings/pretrained_styleEmbedding/rprecision.pickle', 'wb') as handle:\n",
    "    pickle.dump(r_precision_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../models/pickled/embeddings/pretrained_styleEmbedding/mrr.pickle', 'wb') as handle:\n",
    "    pickle.dump(mrr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed7cfc-f31b-442e-8418-7048cfcafecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab60cf9-da48-4266-8d2a-a2773362b411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07376c-edc6-428d-8c15-5a23de98659b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed76a0-3df1-4506-a52e-bb3d79efd752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ac58e58-387e-4e0f-a3fe-f24995802129",
   "metadata": {},
   "source": [
    "# Modified scripts with class frequencies and returned dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c7c46df-21dc-4181-a28f-76c0cc63ecdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, k):\n",
    "    recall_list = []\n",
    "    for act, pred in zip(actual, predicted):\n",
    "        act_set = set(act.numpy())  # Convert PyTorch tensor to NumPy array, then to set\n",
    "        pred_set = set(pred[:k].numpy())  # Convert PyTorch tensor to NumPy array, then to set\n",
    "        \n",
    "        # Check if the actual set is empty to avoid division by zero\n",
    "        if len(act_set) == 0:\n",
    "            recall_list.append(0.0)  # Assign recall as 0 if there are no true labels\n",
    "        else:\n",
    "            recall_list.append(round(len(act_set & pred_set) / float(len(act_set)), 2))\n",
    "    \n",
    "    return recall_list\n",
    "\n",
    "\n",
    "def generate_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)\n",
    "\n",
    "    # Combine train and test labels to compute class frequency across the entire dataset\n",
    "    combined_labels = torch.cat([train_labels, test_labels], dim=0)\n",
    "    unique_vendors = torch.unique(combined_labels)\n",
    "    \n",
    "    # Compute class frequencies from the entire dataset (train + test)\n",
    "    vendor_freq_dict = {int(vendor_id): (combined_labels == vendor_id).sum().item() for vendor_id in unique_vendors}\n",
    "\n",
    "    # Initialize a dict to store scores by frequency\n",
    "    frequency_score_dict = {}\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=\"Calculating R-precision\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if len(test_adsidx) == 0:\n",
    "            continue\n",
    "\n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = test_vendor_embeddings[np.newaxis, :]\n",
    "\n",
    "        k = vendor_freq_dict[vendor_id]  # Use the frequency from the combined dataset\n",
    "        if k == 0:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            _, I = gpu_index_flat.search(test_vendor_embeddings, k)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error searching for vendor_id {vendor_id} with shape {test_vendor_embeddings.shape}: {e}\")\n",
    "            continue\n",
    "\n",
    "        predicted_label_list = [torch.tensor(I[index]) for index in range(len(test_adsidx))]\n",
    "        true_label_list = [torch.where(train_labels == vendor_id)[0] for _ in range(len(test_adsidx))]\n",
    "\n",
    "        score = np.mean(recall_at_k(true_label_list, predicted_label_list, k))\n",
    "\n",
    "        # Track performance score by frequency of instances\n",
    "        freq = vendor_freq_dict[vendor_id]  # Get the frequency from the combined dataset\n",
    "        if freq not in frequency_score_dict:\n",
    "            frequency_score_dict[freq] = []\n",
    "        frequency_score_dict[freq].append(score)\n",
    "\n",
    "    # Calculate average score for each frequency\n",
    "    frequency_avg_score_dict = {freq: np.mean(scores) for freq, scores in frequency_score_dict.items()}\n",
    "\n",
    "    return frequency_avg_score_dict\n",
    "\n",
    "\n",
    "def calculate_mrr_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)\n",
    "\n",
    "    # Combine train and test labels to compute class frequency across the entire dataset\n",
    "    combined_labels = torch.cat([train_labels, test_labels], dim=0)\n",
    "    unique_vendors = torch.unique(combined_labels)\n",
    "\n",
    "    # Compute class frequencies from the entire dataset (train + test)\n",
    "    vendor_freq_dict = {int(vendor_id): (combined_labels == vendor_id).sum().item() for vendor_id in unique_vendors}\n",
    "\n",
    "    # Initialize a dict to store scores by frequency\n",
    "    frequency_score_dict = {}\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=f\"Calculating MRR@{k}\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "        if len(test_adsidx) == 0:\n",
    "            continue\n",
    "\n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = test_vendor_embeddings[np.newaxis, :]\n",
    "\n",
    "        try:\n",
    "            D, I = gpu_index_flat.search(test_vendor_embeddings, k)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error searching for vendor_id {vendor_id} with shape {test_vendor_embeddings.shape}: {e}\")\n",
    "            continue\n",
    "\n",
    "        scores = []\n",
    "        for idx, indices in enumerate(I):\n",
    "            correct_indices = np.where(train_labels.numpy() == vendor_id)[0]\n",
    "            for rank, index in enumerate(indices, start=1):\n",
    "                if index in correct_indices:\n",
    "                    scores.append(1.0 / rank)\n",
    "                    break\n",
    "            else:\n",
    "                scores.append(0.0)\n",
    "\n",
    "        # Track performance score by frequency of instances\n",
    "        freq = vendor_freq_dict[vendor_id]  # Use the frequency from the combined dataset\n",
    "        if freq not in frequency_score_dict:\n",
    "            frequency_score_dict[freq] = []\n",
    "        frequency_score_dict[freq].extend(scores)\n",
    "\n",
    "    # Calculate average MRR score for each frequency\n",
    "    frequency_avg_mrr_dict = {freq: np.mean(scores) for freq, scores in frequency_score_dict.items()}\n",
    "\n",
    "    return frequency_avg_mrr_dict\n",
    "\n",
    "def generate_macro_f1_at_x_results(train_embeddings, train_labels, test_embeddings, test_labels):\n",
    "    dim = train_embeddings.shape[1]\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "    gpu_index_flat.add(train_embeddings)\n",
    "\n",
    "    # Combine train and test labels to compute class frequency across the entire dataset\n",
    "    combined_labels = torch.cat([train_labels, test_labels], dim=0)\n",
    "    unique_vendors = torch.unique(combined_labels)\n",
    "\n",
    "    # Compute class frequencies from the entire dataset (train + test)\n",
    "    vendor_freq_dict = {int(vendor_id): (combined_labels == vendor_id).sum().item() for vendor_id in unique_vendors}\n",
    "\n",
    "    # Initialize a dict to store scores by frequency\n",
    "    frequency_score_dict = {}\n",
    "\n",
    "    for vendor_id in tqdm(unique_vendors, total=len(unique_vendors), desc=\"Calculating Macro-F1@X\"):\n",
    "        vendor_id = int(vendor_id)\n",
    "        test_adsidx = (test_labels == vendor_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if len(test_adsidx) == 0:\n",
    "            continue\n",
    "\n",
    "        test_vendor_embeddings = test_embeddings[test_adsidx]\n",
    "\n",
    "        if isinstance(test_vendor_embeddings, torch.Tensor):\n",
    "            test_vendor_embeddings = test_vendor_embeddings.numpy()\n",
    "\n",
    "        if test_vendor_embeddings.ndim == 1:\n",
    "            test_vendor_embeddings = np.expand_dims(test_vendor_embeddings, axis=0)\n",
    "\n",
    "        k = vendor_freq_dict[vendor_id]  # Use the frequency from the combined dataset\n",
    "        if k > train_embeddings.shape[0]:\n",
    "            k = train_embeddings.shape[0]\n",
    "\n",
    "        _, I = gpu_index_flat.search(test_vendor_embeddings, int(k))\n",
    "\n",
    "        predicted_label_list = [torch.tensor(I[index]) for index in range(len(test_adsidx))]\n",
    "        true_label_list = [torch.where(train_labels == vendor_id)[0] for _ in range(len(test_adsidx))]\n",
    "\n",
    "        f1_scores = f1_at_k(true_label_list, predicted_label_list, k)\n",
    "\n",
    "        # Track performance score by frequency of instances\n",
    "        freq = vendor_freq_dict[vendor_id]  # Use the frequency from the combined dataset\n",
    "        if freq not in frequency_score_dict:\n",
    "            frequency_score_dict[freq] = []\n",
    "        frequency_score_dict[freq].extend(f1_scores)\n",
    "\n",
    "    # Calculate average F1 score for each frequency\n",
    "    frequency_avg_f1_dict = {freq: np.mean(scores) for freq, scores in frequency_score_dict.items()}\n",
    "\n",
    "    return frequency_avg_f1_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2283ebdd-0458-4493-843b-d416a879e37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "City: south\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@10: 100%|██████████| 1463/1463 [00:00<00:00, 5056.92it/s]\n",
      "Calculating R-precision: 100%|██████████| 1463/1463 [00:00<00:00, 3838.33it/s]\n",
      "Calculating Macro-F1@X: 100%|██████████| 1463/1463 [00:00<00:00, 3769.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "City: midwest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@10: 100%|██████████| 1033/1033 [00:00<00:00, 6895.44it/s]\n",
      "Calculating R-precision: 100%|██████████| 1033/1033 [00:00<00:00, 5225.17it/s]\n",
      "Calculating Macro-F1@X: 100%|██████████| 1033/1033 [00:00<00:00, 5057.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "City: west\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@10: 100%|██████████| 520/520 [00:00<00:00, 9378.43it/s]\n",
      "Calculating R-precision: 100%|██████████| 520/520 [00:00<00:00, 7107.28it/s]\n",
      "Calculating Macro-F1@X: 100%|██████████| 520/520 [00:00<00:00, 6714.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "City: northeast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating MRR@10: 100%|██████████| 591/591 [00:00<00:00, 10341.75it/s]\n",
      "Calculating R-precision: 100%|██████████| 591/591 [00:00<00:00, 8541.63it/s]\n",
      "Calculating Macro-F1@X: 100%|██████████| 591/591 [00:00<00:00, 8624.70it/s]\n"
     ]
    }
   ],
   "source": [
    "r_precision_dict, mrr_dict = ({} for i in range(2))\n",
    "for city_ in [\"south\", \"midwest\", \"west\", \"northeast\"]:\n",
    "    print(\"-\"*50)\n",
    "    print(\"City:\", city_)\n",
    "    train_embeddings, train_labels, test_embeddings, test_labels = load_embeddings(model_name=\"declutr\", city=city_)\n",
    "    mrr = calculate_mrr_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10)\n",
    "    rprecision = generate_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    # macro_f1_1 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=1)\n",
    "    # macro_f1_10 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=10)\n",
    "    # macro_f1_100 = calculate_micro_f1_at_k(train_embeddings, train_labels, test_embeddings, test_labels, k=100)\n",
    "    # macro_average_r_precision = generate_macro_rprecision_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "    macro  = generate_macro_f1_at_x_results(train_embeddings, train_labels, test_embeddings, test_labels)\n",
    "\n",
    "    with open(f'/workspace/persistent/HTClipper/results/retrieval/text/mrr/zs_mrr_{city_}.pickle', 'wb') as handle:\n",
    "        pickle.dump(mrr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'/workspace/persistent/HTClipper/results/retrieval/text/rprecision/zs_rprecision_{city_}.pickle', 'wb') as handle:\n",
    "        pickle.dump(rprecision, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'/workspace/persistent/HTClipper/results/retrieval/text/macro-f1/zs_macro_{city_}.pickle', 'wb') as handle:\n",
    "        pickle.dump(macro, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "     \n",
    "    # r_precision_dict[city_] = (r_precision_mean, r_precision_std)\n",
    "    # mrr_dict[city_] = (mrr_mean, mrr_std)\n",
    "    \n",
    "#with open('../models/pickled/embeddings/pretrained_declutr/rprecision.pickle', 'wb') as handle:\n",
    "#    pickle.dump(r_precision_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open('../models/pickled/embeddings/pretrained_declutr/mrr.pickle', 'wb') as handle:\n",
    "#    pickle.dump(mrr_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bbba791-24c0-491c-b07f-51e304ede48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/persistent/HTClipper/results/retrieval/text/mrr/zs_mrr_northeast.pickle', 'rb') as handle:\n",
    "    mrr_zs = pickle.load(handle)\n",
    "    \n",
    "with open('/workspace/persistent/HTClipper/results/retrieval/text/rprecision/zs_rprecision_northeast.pickle', 'rb') as handle:\n",
    "    rprecision_zs = pickle.load(handle)\n",
    "    \n",
    "with open('/workspace/persistent/HTClipper/results/retrieval/text/macro-f1/zs_macro_northeast.pickle', 'rb') as handle:\n",
    "    macro_zs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0801463-3b88-42e3-b3e3-426194fdcc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.2217), (3, 0.3012), (4, 0.4056), (5, 0.5215), (6, 0.4979), (7, 0.7466), (8, 0.4358), (9, 0.8819), (10, 0.5841), (11, 0.3368), (12, 0.7432), (13, 1.0), (14, 1.0), (15, 0.5833), (16, 0.5), (17, 0.28), (18, 0.7381), (19, 0.4667), (21, 1.0), (25, 0.2292), (26, 0.5444), (30, 1.0), (34, 1.0), (35, 0.4583), (43, 1.0)]\n",
      "[(2, 0.2778), (3, 0.2727), (4, 0.4165), (5, 0.4299), (6, 0.4115), (7, 0.6174), (8, 0.3675), (9, 0.6419), (10, 0.43), (11, 0.5833), (12, 0.6826), (13, 0.5), (14, 0.98), (15, 0.4762), (16, 0.62), (17, 0.4667), (18, 0.2958), (19, 0.93), (21, 0.324), (25, 0.0662), (26, 0.4371), (30, 0.94), (34, 0.788), (35, 0.235), (43, 0.5267)]\n",
      "[(2, 0.1572), (3, 0.1938), (4, 0.3125), (5, 0.3116), (6, 0.3195), (7, 0.5215), (8, 0.2901), (9, 0.5876), (10, 0.3912), (11, 0.3646), (12, 0.6038), (13, 0.48), (14, 0.8107), (15, 0.4753), (16, 0.5536), (17, 0.484), (18, 0.2604), (19, 0.7884), (21, 0.2807), (25, 0.0536), (26, 0.3567), (30, 0.8343), (34, 0.7246), (35, 0.2133), (43, 0.4851)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted({k:round(v,4) for k, v in mrr_zs.items()}.items()))\n",
    "print(sorted({k:round(v,4) for k, v in rprecision_zs.items()}.items()))\n",
    "print(sorted({k:round(v,4) for k, v in macro_zs.items()}.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84804e3-0537-4e58-ae4d-533e6a724678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HT",
   "language": "python",
   "name": "ht"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
